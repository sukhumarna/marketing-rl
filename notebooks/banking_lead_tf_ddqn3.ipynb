{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb7c9b56-0b9d-48e6-9ad0-912fa10ff547",
   "metadata": {},
   "source": [
    "# DDQN Model with Flexible Reward Environment for Banking Lead Conversion Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ba103a1-77f6-4252-97b2-24830f287726",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "curr_folder = globals()['_dh']\n",
    "\n",
    "os.chdir(os.path.join(curr_folder[0], '..'))\n",
    "sys.path.append(os.path.join(curr_folder[0], '..'))\n",
    "sys.path.append(os.path.join(curr_folder[0], '../marketing_rl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d7d6cc2-7949-4225-a6e8-677331659eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report, roc_curve, roc_auc_score, auc, confusion_matrix, fbeta_score\n",
    "\n",
    "import tensorflow as tf\n",
    "import tf_agents.utils.common as common\n",
    "from tf_agents.agents.dqn import dqn_agent\n",
    "from tf_agents.drivers import dynamic_step_driver\n",
    "from tf_agents.networks.q_network import QNetwork\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.replay_buffers import TFUniformReplayBuffer\n",
    "\n",
    "from marketing_rl.environment.flexi_biclass_tf_env import FlexiBiClassTFEnv, EnvMode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04e376e-d1d5-49e2-bcbd-4b3c9a63547e",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "990b942e-6320-485b-8033-36d232a912da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data size is 69713\n"
     ]
    }
   ],
   "source": [
    "data_path = 'data/Banking | Marketing | Leads Conversion Data/train_loan/train.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "print('total data size is', df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45a9ec7-6509-4b4c-a90a-8e41ee2feb87",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f16f2c32-0a97-48ec-9df5-f9e375de1e1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6025275056302268"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['DOB'] = df['DOB'].apply(pd.to_datetime)\n",
    "df['Lead_Creation_Date'] = df['Lead_Creation_Date'].apply(pd.to_datetime)\n",
    "df['Age'] = (df['Lead_Creation_Date'] - df['DOB'])/ np.timedelta64(1, 'Y')\n",
    "df['Age'] = np.where(df['Age'] < 0, np.nan, df['Age'])\n",
    "df['Apply'] = np.where(df['Loan_Amount']>0, 1, 0)\n",
    "df['Apply'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8334307-f8f9-4a1b-aa3a-8a7cc3abf73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_col = 'Apply'\n",
    "index_col = 'ID'\n",
    "date_col = 'Lead_Creation_Date'\n",
    "feat_cols = ['Gender', 'Age', 'City_Category', 'Employer_Category1', 'Employer_Category2', \n",
    "             'Monthly_Income', 'Primary_Bank_Type',\n",
    "             'Source_Category', 'Existing_EMI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b848852-bfc2-48e9-acde-b159fdf9e653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size is 45576\n",
      "test size is 24137\n"
     ]
    }
   ],
   "source": [
    "test_cond = df['Lead_Creation_Date'] > '2016-09-01'\n",
    "train_df = df.loc[~test_cond, :].copy()\n",
    "test_df = df.loc[test_cond, :].copy()\n",
    "print('train size is', train_df.shape[0])\n",
    "print('test size is', test_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d98a2115-9997-44e7-a3d7-279d266c5e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size is 45576\n",
      "test size is 24137\n"
     ]
    }
   ],
   "source": [
    "X_train = train_df[feat_cols]\n",
    "y_train = train_df[label_col]\n",
    "X_test = test_df[feat_cols]\n",
    "y_test = test_df[label_col]\n",
    "print('train size is', X_train.shape[0])\n",
    "print('test size is', X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c639a54d-5b4b-4da7-a032-721bdba6bd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "numer_feats = ['Age', 'Monthly_Income', 'Existing_EMI']\n",
    "numer_transformer = Pipeline(\n",
    "    steps=[(\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", StandardScaler())]\n",
    ")\n",
    "\n",
    "cat_feats = ['Gender', 'City_Category', 'Employer_Category1', 'Employer_Category2', \n",
    "             'Primary_Bank_Type', 'Source_Category']\n",
    "cat_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numer_transformer, numer_feats),\n",
    "        # (\"ordinal\", binary_transformer, binary_feats),\n",
    "        (\"cat\", cat_transformer, cat_feats)\n",
    "    ], sparse_threshold = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4239089-7068-4fb8-b8c3-00f3053a2dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_t = transformer.fit_transform(X_train)\n",
    "X_test_t = transformer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c81d4817-3a74-44bb-b27a-02d9a78462e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sukhumarn/anaconda3/envs/mar_rl/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "transformers = transformer.get_params()['transformers']\n",
    "feature_names = []\n",
    "for name, _, features in transformers:\n",
    "    try:\n",
    "        Var = transformer.named_transformers_[name].get_feature_names().tolist()\n",
    "    except AttributeError:\n",
    "        Var = features\n",
    "    feature_names = feature_names + Var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70be69ee-59d8-44e6-9882-685bcb6cf9cd",
   "metadata": {},
   "source": [
    "## Prep Agents Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04ef89bc-bb59-489f-b4ef-934c4c65f949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] positive sample to negative sample is 1.595296395421673\n"
     ]
    }
   ],
   "source": [
    "pos_neg_ratio = sum(y_train==1)/sum(y_train==0)\n",
    "print('[train] positive sample to negative sample is', pos_neg_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5974277f-fe4c-41c4-8ec7-d2386f92944c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] early stop is 22788.0\n"
     ]
    }
   ],
   "source": [
    "early_stop = train_df.shape[0] * 0.5\n",
    "print(f'[train] early stop is {early_stop}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c74cc566-c069-485f-9306-82fb6309d68b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     28015.000000\n",
       "mean      39237.943959\n",
       "std       30192.645464\n",
       "min        5000.000000\n",
       "25%       20000.000000\n",
       "50%       30000.000000\n",
       "75%       50000.000000\n",
       "max      300000.000000\n",
       "Name: Loan_Amount, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Loan_Amount'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff44e086-2964-4a9e-9a72-b77170f69d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(value, min_val, max_val):\n",
    "    new_value = (value -  min_val)/(max_val - min_val)\n",
    "    return new_value\n",
    "train_df['add_reward'] = train_df['Loan_Amount'].apply(lambda x: normalize_data(x, 5000, 100000))\n",
    "train_df.fillna(0, inplace=True)\n",
    "train_df['add_reward'] = train_df['add_reward'].clip(0, 1)\n",
    "train_df['total_reward'] = train_df['Apply'] + train_df['add_reward']\n",
    "\n",
    "test_df['add_reward'] = test_df['Loan_Amount'].apply(lambda x: normalize_data(x, 5000, 100000))\n",
    "test_df.fillna(0, inplace=True)\n",
    "test_df['add_reward'] = test_df['add_reward'].clip(0, 1)\n",
    "test_df['total_reward'] = test_df['Apply'] + test_df['add_reward']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e08c5e68-b2b2-4b07-af2c-f79483b8e7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_x = np.array(X_train_t)\n",
    "train_data_y = np.array(y_train)\n",
    "reward = np.array(train_df['total_reward'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff72a0cc-08b2-44cb-b515-dfd56cd28a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_env = FlexiBiClassTFEnv(data_x=train_data_x, data_y=train_data_y, pos_neg_ratio=1, \n",
    "                              discount=0.05, reward=reward, early_stop=early_stop)\n",
    "train_tf_env = tf_py_environment.TFPyEnvironment(train_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58c6f240-c516-47fb-9c00-a949e3d1a706",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data_x = np.array(X_test_t)\n",
    "eval_data_y = np.array(y_test)\n",
    "eval_reward = np.array(test_df['total_reward'])\n",
    "\n",
    "eval_env = FlexiBiClassTFEnv(data_x=eval_data_x, data_y=eval_data_y, reward=eval_reward, \n",
    "                        pos_neg_ratio=1, mode=EnvMode.TEST)\n",
    "eval_tf_env = tf_py_environment.TFPyEnvironment(eval_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4d320d-28d8-4a06-8c71-f8092e85d9e6",
   "metadata": {},
   "source": [
    "## Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991156f5-6c80-4b58-98fc-5cb5091d2800",
   "metadata": {},
   "source": [
    "### Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d5eff2fe-23d6-4533-8c61-b62892d7897e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameters\n",
    "fc_layers = (128, 32)\n",
    "learning_rate = 1e-5\n",
    "batch_size = 64\n",
    "replay_buffer_capacity = 100000\n",
    "\n",
    "num_iterations = 50000\n",
    "num_eval_episodes = 1\n",
    "\n",
    "log_interval = 200\n",
    "eval_interval = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401cbe00-0b95-4857-8ea8-69e4d829edcb",
   "metadata": {},
   "source": [
    "### Set Q-network and initialize agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8cd8b570-d2e7-49bf-b0df-b670f27c00cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-15 11:20:45.041125: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# q network\n",
    "q_net = QNetwork(\n",
    "    input_tensor_spec = train_tf_env.observation_spec(),\n",
    "    action_spec = train_tf_env.action_spec(),\n",
    "    fc_layer_params = fc_layers,\n",
    ")\n",
    "\n",
    "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "# train_step_counter = tf.compat.v2.Variable(0)\n",
    "global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "\n",
    "# ddqn agent\n",
    "agent = dqn_agent.DdqnAgent(\n",
    "    time_step_spec = train_tf_env.time_step_spec(),\n",
    "    action_spec = train_tf_env.action_spec(),\n",
    "    q_network = q_net,\n",
    "    optimizer = optimizer,\n",
    "    td_errors_loss_fn = common.element_wise_squared_loss,\n",
    "    train_step_counter = global_step,\n",
    "    emit_log_probability = True\n",
    ")\n",
    "agent.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8decdd0-20a9-424a-adc8-d2e2186e95df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size: None\n"
     ]
    }
   ],
   "source": [
    "# initiate replay buffer for training\n",
    "replay_buffer = TFUniformReplayBuffer(\n",
    "    data_spec = agent.collect_data_spec,\n",
    "    batch_size = train_tf_env.batch_size,\n",
    "    max_length = replay_buffer_capacity,\n",
    ")\n",
    "print(\"Batch Size: {}\".format(train_env.batch_size))\n",
    "\n",
    "replay_observer = [replay_buffer.add_batch]\n",
    "metrics = [\n",
    "    tf_metrics.NumberOfEpisodes(),\n",
    "    tf_metrics.EnvironmentSteps(),\n",
    "    tf_metrics.AverageReturnMetric(),\n",
    "    tf_metrics.AverageEpisodeLengthMetric(),\n",
    "    \n",
    "]\n",
    "\n",
    "# policy\n",
    "eval_policy = agent.policy\n",
    "collect_policy = agent.collect_policy\n",
    "\n",
    "agent.train = common.function(agent.train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b985028-cb8d-4257-95ca-0bee3743a778",
   "metadata": {},
   "source": [
    "### Set Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22d09c99-784f-4e10-ae88-69f309e5d6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_folder = 'banking_lead_ddqn_cp3'\n",
    "train_checkpointer = common.Checkpointer(\n",
    "    ckpt_dir=checkpoint_folder,\n",
    "    max_to_keep=1,\n",
    "    agent=agent,\n",
    "    policy=agent.policy,\n",
    "    replay_buffer=replay_buffer,\n",
    "    global_step=global_step\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a00864-8a9c-4971-a5c9-56967df8b379",
   "metadata": {},
   "source": [
    "### Set Dataset Iteration and Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "313bb481-e000-41ab-9f32-1b40703b6ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/sukhumarn/anaconda3/envs/mar_rl/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:377: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `as_dataset(..., single_deterministic_pass=False) instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/sukhumarn/anaconda3/envs/mar_rl/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:377: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `as_dataset(..., single_deterministic_pass=False) instead.\n"
     ]
    }
   ],
   "source": [
    "dataset = replay_buffer.as_dataset(\n",
    "    num_parallel_calls = 3, \n",
    "    sample_batch_size = batch_size,\n",
    "    num_steps = 2\n",
    ").prefetch(3)\n",
    "\n",
    "driver = dynamic_step_driver.DynamicStepDriver(\n",
    "    env = train_tf_env,\n",
    "    policy = collect_policy,\n",
    "    observers = replay_observer + metrics,\n",
    ")\n",
    "\n",
    "data_iter = iter(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa06940e-9b5b-4fea-b20b-a2182747afc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_avg_return(environment, policy, num_episodes=1):\n",
    "    total_return = 0.0\n",
    "    total_step = 0\n",
    "    for i in range(num_episodes):\n",
    "        time_step = environment.reset()\n",
    "        episode_return = 0.0\n",
    "\n",
    "        while not time_step.is_last():\n",
    "            action_step = policy.action(time_step)\n",
    "            time_step = environment.step(action_step.action)\n",
    "            episode_return += time_step.reward\n",
    "            total_step += 1\n",
    "        total_return += episode_return\n",
    "            \n",
    "    print(f'total step is {total_step}')\n",
    "    print(f'total reward is {total_return}')\n",
    "    avg_return = total_return / num_episodes\n",
    "    return avg_return.numpy()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96f3438-54ab-417d-b80f-5aead5241f87",
   "metadata": {},
   "source": [
    "### Train agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7216fc10-b81b-4b56-8157-a6026e185a1e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/sukhumarn/anaconda3/envs/mar_rl/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1082: calling foldr_v2 (from tensorflow.python.ops.functional_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.foldr(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.foldr(fn, elems))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/sukhumarn/anaconda3/envs/mar_rl/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1082: calling foldr_v2 (from tensorflow.python.ops.functional_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.foldr(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.foldr(fn, elems))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 200: loss = 1.5885517597198486\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  201\n",
      "step = 400: loss = 1.5118829011917114\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  401\n",
      "step = 600: loss = 1.404030203819275\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  601\n",
      "step = 800: loss = 1.6706645488739014\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  801\n",
      "step = 1000: loss = 1.5485508441925049\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  1001\n",
      "total step is 24137\n",
      "total reward is [8701.696]\n",
      "step = 1000: Average Return = 8701.6962890625\n",
      "step = 1200: loss = 1.4130843877792358\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  1201\n",
      "step = 1400: loss = 1.4029529094696045\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  1401\n",
      "step = 1600: loss = 1.3745512962341309\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  1601\n",
      "step = 1800: loss = 1.1992971897125244\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  1801\n",
      "step = 2000: loss = 1.1398422718048096\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  2001\n",
      "total step is 24137\n",
      "total reward is [8701.689]\n",
      "step = 2000: Average Return = 8701.689453125\n",
      "step = 2200: loss = 1.181467056274414\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  2201\n",
      "step = 2400: loss = 1.0942420959472656\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  2401\n",
      "step = 2600: loss = 0.9938207864761353\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  2601\n",
      "step = 2800: loss = 0.9434123039245605\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  2801\n",
      "step = 3000: loss = 0.8312479853630066\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  3001\n",
      "total step is 24137\n",
      "total reward is [9321.697]\n",
      "step = 3000: Average Return = 9321.697265625\n",
      "step = 3200: loss = 0.821995735168457\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  3201\n",
      "step = 3400: loss = 0.7643147706985474\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  3401\n",
      "step = 3600: loss = 0.6192525625228882\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  3601\n",
      "step = 3800: loss = 0.7261860966682434\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  3801\n",
      "step = 4000: loss = 0.6636345982551575\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  4001\n",
      "total step is 24137\n",
      "total reward is [13489.645]\n",
      "step = 4000: Average Return = 13489.64453125\n",
      "step = 4200: loss = 0.5149383544921875\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  4201\n",
      "step = 4400: loss = 0.6469612717628479\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  4401\n",
      "step = 4600: loss = 0.5075367093086243\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  4601\n",
      "step = 4800: loss = 0.5152114629745483\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  4801\n",
      "step = 5000: loss = 0.5420103073120117\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  5001\n",
      "total step is 24137\n",
      "total reward is [20768.275]\n",
      "step = 5000: Average Return = 20768.275390625\n",
      "step = 5200: loss = 0.5232200622558594\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  5201\n",
      "step = 5400: loss = 0.5241290330886841\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  5401\n",
      "step = 5600: loss = 0.3634805679321289\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  5601\n",
      "step = 5800: loss = 0.6464143991470337\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  5801\n",
      "step = 6000: loss = 0.4828881025314331\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  6001\n",
      "total step is 24137\n",
      "total reward is [22556.158]\n",
      "step = 6000: Average Return = 22556.158203125\n",
      "step = 6200: loss = 0.4313756823539734\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  6201\n",
      "step = 6400: loss = 0.5175086259841919\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  6401\n",
      "step = 6600: loss = 0.35895833373069763\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  6601\n",
      "step = 6800: loss = 0.34639081358909607\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  6801\n",
      "step = 7000: loss = 0.33373695611953735\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  7001\n",
      "total step is 24137\n",
      "total reward is [23248.018]\n",
      "step = 7000: Average Return = 23248.017578125\n",
      "step = 7200: loss = 0.3986794054508209\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  7201\n",
      "step = 7400: loss = 0.49334245920181274\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  7401\n",
      "step = 7600: loss = 0.4885437488555908\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  7601\n",
      "step = 7800: loss = 0.47755736112594604\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  7801\n",
      "step = 8000: loss = 0.23202502727508545\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  8001\n",
      "total step is 24137\n",
      "total reward is [23464.936]\n",
      "step = 8000: Average Return = 23464.935546875\n",
      "step = 8200: loss = 0.32459917664527893\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  8201\n",
      "step = 8400: loss = 0.2514302730560303\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  8401\n",
      "step = 8600: loss = 0.4103163778781891\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  8601\n",
      "step = 8800: loss = 0.40813571214675903\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  8801\n",
      "step = 9000: loss = 0.4924173653125763\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  9001\n",
      "total step is 24137\n",
      "total reward is [23512.12]\n",
      "step = 9000: Average Return = 23512.119140625\n",
      "step = 9200: loss = 0.43159326910972595\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  9201\n",
      "step = 9400: loss = 0.624049723148346\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  9401\n",
      "step = 9600: loss = 0.5517827272415161\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  9601\n",
      "step = 9800: loss = 0.6155165433883667\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  9801\n",
      "step = 10000: loss = 0.4648198187351227\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  10001\n",
      "total step is 24137\n",
      "total reward is [23511.77]\n",
      "step = 10000: Average Return = 23511.76953125\n",
      "step = 10200: loss = 0.35196590423583984\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  10201\n",
      "step = 10400: loss = 0.2604604959487915\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  10401\n",
      "step = 10600: loss = 0.2776150405406952\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  10601\n",
      "step = 10800: loss = 0.2719842195510864\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  10801\n",
      "step = 11000: loss = 0.2658981382846832\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  11001\n",
      "total step is 24137\n",
      "total reward is [23511.746]\n",
      "step = 11000: Average Return = 23511.74609375\n",
      "step = 11200: loss = 0.3583802282810211\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  11201\n",
      "step = 11400: loss = 0.40602588653564453\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  11401\n",
      "step = 11600: loss = 0.4252324104309082\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  11601\n",
      "step = 11800: loss = 0.5076252222061157\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  11801\n",
      "step = 12000: loss = 0.3587322235107422\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  12001\n",
      "total step is 24137\n",
      "total reward is [23506.377]\n",
      "step = 12000: Average Return = 23506.376953125\n",
      "step = 12200: loss = 0.38067975640296936\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  12201\n",
      "step = 12400: loss = 0.27951598167419434\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  12401\n",
      "step = 12600: loss = 0.36413708329200745\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  12601\n",
      "step = 12800: loss = 0.13705280423164368\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  12801\n",
      "step = 13000: loss = 0.2977295517921448\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  13001\n",
      "total step is 24137\n",
      "total reward is [23514.443]\n",
      "step = 13000: Average Return = 23514.443359375\n",
      "step = 13200: loss = 0.25055715441703796\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  13201\n",
      "step = 13400: loss = 0.45486778020858765\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  13401\n",
      "step = 13600: loss = 0.28628742694854736\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  13601\n",
      "step = 13800: loss = 0.29302382469177246\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  13801\n",
      "step = 14000: loss = 0.30421483516693115\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  14001\n",
      "total step is 24137\n",
      "total reward is [23514.426]\n",
      "step = 14000: Average Return = 23514.42578125\n",
      "step = 14200: loss = 0.3745030164718628\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  14201\n",
      "step = 14400: loss = 0.42399361729621887\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  14401\n",
      "step = 14600: loss = 0.2508695423603058\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  14601\n",
      "step = 14800: loss = 0.27841565012931824\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  14801\n",
      "step = 15000: loss = 0.42571592330932617\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  15001\n",
      "total step is 24137\n",
      "total reward is [23517.785]\n",
      "step = 15000: Average Return = 23517.78515625\n",
      "step = 15200: loss = 0.40561217069625854\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  15201\n",
      "step = 15400: loss = 0.22784461081027985\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  15401\n",
      "step = 15600: loss = 0.5196543335914612\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  15601\n",
      "step = 15800: loss = 0.3840301036834717\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  15801\n",
      "step = 16000: loss = 0.22232288122177124\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  16001\n",
      "total step is 24137\n",
      "total reward is [23509.32]\n",
      "step = 16000: Average Return = 23509.3203125\n",
      "step = 16200: loss = 0.4420894384384155\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  16201\n",
      "step = 16400: loss = 0.1511644423007965\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  16401\n",
      "step = 16600: loss = 0.315108060836792\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  16601\n",
      "step = 16800: loss = 0.5117591023445129\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  16801\n",
      "step = 17000: loss = 0.47456586360931396\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  17001\n",
      "total step is 24137\n",
      "total reward is [23513.016]\n",
      "step = 17000: Average Return = 23513.015625\n",
      "step = 17200: loss = 0.3920946419239044\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  17201\n",
      "step = 17400: loss = 0.2171408236026764\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  17401\n",
      "step = 17600: loss = 0.12143934518098831\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  17601\n",
      "step = 17800: loss = 0.2862454056739807\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  17801\n",
      "step = 18000: loss = 0.2912329435348511\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  18001\n",
      "total step is 24137\n",
      "total reward is [23516.008]\n",
      "step = 18000: Average Return = 23516.0078125\n",
      "step = 18200: loss = 0.35012757778167725\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  18201\n",
      "step = 18400: loss = 0.41409164667129517\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  18401\n",
      "step = 18600: loss = 0.4834612011909485\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  18601\n",
      "step = 18800: loss = 0.21805141866207123\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  18801\n",
      "step = 19000: loss = 0.2883305847644806\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  19001\n",
      "total step is 24137\n",
      "total reward is [23516.062]\n",
      "step = 19000: Average Return = 23516.0625\n",
      "step = 19200: loss = 0.4723093807697296\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  19201\n",
      "step = 19400: loss = 0.427371084690094\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  19401\n",
      "step = 19600: loss = 0.48921188712120056\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  19601\n",
      "step = 19800: loss = 0.2646244466304779\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  19801\n",
      "step = 20000: loss = 0.4607425928115845\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  20001\n",
      "total step is 24137\n",
      "total reward is [23515.99]\n",
      "step = 20000: Average Return = 23515.990234375\n",
      "step = 20200: loss = 0.25481748580932617\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  20201\n",
      "step = 20400: loss = 0.2627415060997009\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  20401\n",
      "step = 20600: loss = 0.41379213333129883\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  20601\n",
      "step = 20800: loss = 0.2840445041656494\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  20801\n",
      "step = 21000: loss = 0.3326188623905182\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  21001\n",
      "total step is 24137\n",
      "total reward is [23512.064]\n",
      "step = 21000: Average Return = 23512.064453125\n",
      "step = 21200: loss = 0.2050376832485199\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  21201\n",
      "step = 21400: loss = 0.5091627836227417\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  21401\n",
      "step = 21600: loss = 0.46278202533721924\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  21601\n",
      "step = 21800: loss = 0.2149031162261963\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  21801\n",
      "step = 22000: loss = 0.29882028698921204\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  22001\n",
      "total step is 24137\n",
      "total reward is [23510.035]\n",
      "step = 22000: Average Return = 23510.03515625\n",
      "step = 22200: loss = 0.38342663645744324\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  22201\n",
      "step = 22400: loss = 0.4063316583633423\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  22401\n",
      "step = 22600: loss = 0.35205361247062683\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  22601\n",
      "step = 22800: loss = 0.5752404928207397\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  22801\n",
      "step = 23000: loss = 0.22685475647449493\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  23001\n",
      "total step is 24137\n",
      "total reward is [23510.02]\n",
      "step = 23000: Average Return = 23510.01953125\n",
      "step = 23200: loss = 0.2591975927352905\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  23201\n",
      "step = 23400: loss = 0.41982096433639526\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  23401\n",
      "step = 23600: loss = 0.2944523096084595\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  23601\n",
      "step = 23800: loss = 0.3114006221294403\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  23801\n",
      "step = 24000: loss = 0.2500080466270447\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  24001\n",
      "total step is 24137\n",
      "total reward is [23516.91]\n",
      "step = 24000: Average Return = 23516.91015625\n",
      "step = 24200: loss = 0.31981316208839417\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  24201\n",
      "step = 24400: loss = 0.4547783136367798\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  24401\n",
      "step = 24600: loss = 0.5850241184234619\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  24601\n",
      "step = 24800: loss = 0.2532900273799896\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  24801\n",
      "step = 25000: loss = 0.34547483921051025\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  25001\n",
      "total step is 24137\n",
      "total reward is [23513.592]\n",
      "step = 25000: Average Return = 23513.591796875\n",
      "step = 25200: loss = 0.23366057872772217\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  25201\n",
      "step = 25400: loss = 0.2856579124927521\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  25401\n",
      "step = 25600: loss = 0.46217334270477295\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  25601\n",
      "step = 25800: loss = 0.22657716274261475\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  25801\n",
      "step = 26000: loss = 0.4443613290786743\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  26001\n",
      "total step is 24137\n",
      "total reward is [23513.666]\n",
      "step = 26000: Average Return = 23513.666015625\n",
      "step = 26200: loss = 0.24913042783737183\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  26201\n",
      "step = 26400: loss = 0.23133087158203125\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  26401\n",
      "step = 26600: loss = 0.5110113620758057\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  26601\n",
      "step = 26800: loss = 0.2799212336540222\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  26801\n",
      "step = 27000: loss = 0.36467671394348145\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  27001\n",
      "total step is 24137\n",
      "total reward is [23527.326]\n",
      "step = 27000: Average Return = 23527.326171875\n",
      "step = 27200: loss = 0.34919291734695435\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  27201\n",
      "step = 27400: loss = 0.5068827867507935\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  27401\n",
      "step = 27600: loss = 0.18084993958473206\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  27601\n",
      "step = 27800: loss = 0.48252925276756287\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  27801\n",
      "step = 28000: loss = 0.4580661356449127\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  28001\n",
      "total step is 24137\n",
      "total reward is [23526.736]\n",
      "step = 28000: Average Return = 23526.736328125\n",
      "step = 28200: loss = 0.46331876516342163\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  28201\n",
      "step = 28400: loss = 0.2592622637748718\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  28401\n",
      "step = 28600: loss = 0.3244608938694\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  28601\n",
      "step = 28800: loss = 0.3653579354286194\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  28801\n",
      "step = 29000: loss = 0.5338903665542603\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  29001\n",
      "total step is 24137\n",
      "total reward is [23568.29]\n",
      "step = 29000: Average Return = 23568.2890625\n",
      "step = 29200: loss = 0.36525458097457886\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  29201\n",
      "step = 29400: loss = 0.20246705412864685\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  29401\n",
      "step = 29600: loss = 0.43401026725769043\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  29601\n",
      "step = 29800: loss = 0.2997263967990875\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  29801\n",
      "step = 30000: loss = 0.35048818588256836\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  30001\n",
      "total step is 24137\n",
      "total reward is [23568.32]\n",
      "step = 30000: Average Return = 23568.3203125\n",
      "step = 30200: loss = 0.671911895275116\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  30201\n",
      "step = 30400: loss = 0.37065139412879944\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  30401\n",
      "step = 30600: loss = 0.38816025853157043\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  30601\n",
      "step = 30800: loss = 0.2582675814628601\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  30801\n",
      "step = 31000: loss = 0.37554287910461426\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  31001\n",
      "total step is 24137\n",
      "total reward is [23586.688]\n",
      "step = 31000: Average Return = 23586.6875\n",
      "step = 31200: loss = 0.358095645904541\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  31201\n",
      "step = 31400: loss = 0.2871713638305664\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  31401\n",
      "step = 31600: loss = 0.33151155710220337\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  31601\n",
      "step = 31800: loss = 0.5324709415435791\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  31801\n",
      "step = 32000: loss = 0.2863759994506836\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  32001\n",
      "total step is 24137\n",
      "total reward is [23582.336]\n",
      "step = 32000: Average Return = 23582.3359375\n",
      "step = 32200: loss = 0.2677185535430908\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  32201\n",
      "step = 32400: loss = 0.25389909744262695\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  32401\n",
      "step = 32600: loss = 0.32805135846138\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  32601\n",
      "step = 32800: loss = 0.399026095867157\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  32801\n",
      "step = 33000: loss = 0.42567235231399536\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  33001\n",
      "total step is 24137\n",
      "total reward is [23590.84]\n",
      "step = 33000: Average Return = 23590.83984375\n",
      "step = 33200: loss = 0.39015087485313416\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  33201\n",
      "step = 33400: loss = 0.21985062956809998\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  33401\n",
      "step = 33600: loss = 0.3840193748474121\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  33601\n",
      "step = 33800: loss = 0.2363155484199524\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  33801\n",
      "step = 34000: loss = 0.19808503985404968\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  34001\n",
      "total step is 24137\n",
      "total reward is [23591.463]\n",
      "step = 34000: Average Return = 23591.462890625\n",
      "step = 34200: loss = 0.5086306929588318\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  34201\n",
      "step = 34400: loss = 0.4146580398082733\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  34401\n",
      "step = 34600: loss = 0.32262179255485535\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  34601\n",
      "step = 34800: loss = 0.29194629192352295\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  34801\n",
      "step = 35000: loss = 0.2708691954612732\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  35001\n",
      "total step is 24137\n",
      "total reward is [23591.39]\n",
      "step = 35000: Average Return = 23591.390625\n",
      "step = 35200: loss = 0.3064015209674835\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  35201\n",
      "step = 35400: loss = 0.4299204647541046\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  35401\n",
      "step = 35600: loss = 0.3500400185585022\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  35601\n",
      "step = 35800: loss = 0.4229041635990143\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  35801\n",
      "step = 36000: loss = 0.22211337089538574\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  36001\n",
      "total step is 24137\n",
      "total reward is [23590.336]\n",
      "step = 36000: Average Return = 23590.3359375\n",
      "step = 36200: loss = 0.26192837953567505\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  36201\n",
      "step = 36400: loss = 0.2679934501647949\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  36401\n",
      "step = 36600: loss = 0.5767859220504761\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  36601\n",
      "step = 36800: loss = 0.3347148895263672\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  36801\n",
      "step = 37000: loss = 0.2844678461551666\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  37001\n",
      "total step is 24137\n",
      "total reward is [23593.168]\n",
      "step = 37000: Average Return = 23593.16796875\n",
      "step = 37200: loss = 0.2840334177017212\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  37201\n",
      "step = 37400: loss = 0.36877888441085815\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  37401\n",
      "step = 37600: loss = 0.5068731904029846\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  37601\n",
      "step = 37800: loss = 0.49593019485473633\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  37801\n",
      "step = 38000: loss = 0.2879619598388672\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  38001\n",
      "total step is 24137\n",
      "total reward is [23593.145]\n",
      "step = 38000: Average Return = 23593.14453125\n",
      "step = 38200: loss = 0.49594032764434814\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  38201\n",
      "step = 38400: loss = 0.3459160029888153\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  38401\n",
      "step = 38600: loss = 0.24625322222709656\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  38601\n",
      "step = 38800: loss = 0.6007200479507446\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  38801\n",
      "step = 39000: loss = 0.6033780574798584\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  39001\n",
      "total step is 24137\n",
      "total reward is [23605.879]\n",
      "step = 39000: Average Return = 23605.87890625\n",
      "step = 39200: loss = 0.4316374957561493\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  39201\n",
      "step = 39400: loss = 0.38349586725234985\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  39401\n",
      "step = 39600: loss = 0.46869707107543945\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  39601\n",
      "step = 39800: loss = 0.39275887608528137\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  39801\n",
      "step = 40000: loss = 0.40656715631484985\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  40001\n",
      "total step is 24137\n",
      "total reward is [23700.46]\n",
      "step = 40000: Average Return = 23700.4609375\n",
      "step = 40200: loss = 0.28644248843193054\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  40201\n",
      "step = 40400: loss = 0.5693538188934326\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  40401\n",
      "step = 40600: loss = 0.13127613067626953\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  40601\n",
      "step = 40800: loss = 0.3948255777359009\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  40801\n",
      "step = 41000: loss = 0.1579575538635254\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  41001\n",
      "total step is 24137\n",
      "total reward is [23699.465]\n",
      "step = 41000: Average Return = 23699.46484375\n",
      "step = 41200: loss = 0.38475120067596436\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  41201\n",
      "step = 41400: loss = 0.28256869316101074\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  41401\n",
      "step = 41600: loss = 0.35714274644851685\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  41601\n",
      "step = 41800: loss = 0.34860360622406006\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  41801\n",
      "step = 42000: loss = 0.3434489965438843\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  42001\n",
      "total step is 24137\n",
      "total reward is [23707.51]\n",
      "step = 42000: Average Return = 23707.509765625\n",
      "step = 42200: loss = 0.20039427280426025\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  42201\n",
      "step = 42400: loss = 0.30052420496940613\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  42401\n",
      "step = 42600: loss = 0.47034454345703125\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  42601\n",
      "step = 42800: loss = 0.38162142038345337\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  42801\n",
      "step = 43000: loss = 0.3163282573223114\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  43001\n",
      "total step is 24137\n",
      "total reward is [23703.506]\n",
      "step = 43000: Average Return = 23703.505859375\n",
      "step = 43200: loss = 0.24768710136413574\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  43201\n",
      "step = 43400: loss = 0.49247410893440247\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  43401\n",
      "step = 43600: loss = 0.4259525537490845\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  43601\n",
      "step = 43800: loss = 0.3377920389175415\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  43801\n",
      "step = 44000: loss = 0.47834861278533936\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  44001\n",
      "total step is 24137\n",
      "total reward is [23707.559]\n",
      "step = 44000: Average Return = 23707.55859375\n",
      "step = 44200: loss = 0.35703834891319275\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  44201\n",
      "step = 44400: loss = 0.5945481061935425\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  44401\n",
      "step = 44600: loss = 0.26765739917755127\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  44601\n",
      "step = 44800: loss = 0.1776605248451233\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  44801\n",
      "step = 45000: loss = 0.39285409450531006\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  45001\n",
      "total step is 24137\n",
      "total reward is [23709.557]\n",
      "step = 45000: Average Return = 23709.556640625\n",
      "step = 45200: loss = 0.21102318167686462\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  45201\n",
      "step = 45400: loss = 0.5844292640686035\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  45401\n",
      "step = 45600: loss = 0.29027754068374634\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  45601\n",
      "step = 45800: loss = 0.4640995264053345\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  45801\n",
      "step = 46000: loss = 0.27043503522872925\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  46001\n",
      "total step is 24137\n",
      "total reward is [23707.562]\n",
      "step = 46000: Average Return = 23707.5625\n",
      "step = 46200: loss = 0.35414934158325195\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  46201\n",
      "step = 46400: loss = 0.49188339710235596\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  46401\n",
      "step = 46600: loss = 0.2951829433441162\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  46601\n",
      "step = 46800: loss = 0.44323059916496277\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  46801\n",
      "step = 47000: loss = 0.5137615203857422\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  47001\n",
      "total step is 24137\n",
      "total reward is [23709.98]\n",
      "step = 47000: Average Return = 23709.98046875\n",
      "step = 47200: loss = 0.3977707624435425\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  47201\n",
      "step = 47400: loss = 0.26517608761787415\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  47401\n",
      "step = 47600: loss = 0.30215349793434143\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  47601\n",
      "step = 47800: loss = 0.2910025715827942\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  47801\n",
      "step = 48000: loss = 0.42230886220932007\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  48001\n",
      "total step is 24137\n",
      "total reward is [23711.307]\n",
      "step = 48000: Average Return = 23711.306640625\n",
      "step = 48200: loss = 0.3577120304107666\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  48201\n",
      "step = 48400: loss = 0.45870697498321533\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  48401\n",
      "step = 48600: loss = 0.3153188228607178\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  48601\n",
      "step = 48800: loss = 0.3219653367996216\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  48801\n",
      "step = 49000: loss = 0.5555601119995117\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  49001\n",
      "total step is 24137\n",
      "total reward is [23707.967]\n",
      "step = 49000: Average Return = 23707.966796875\n",
      "step = 49200: loss = 0.4151940643787384\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  49201\n",
      "step = 49400: loss = 0.2031034529209137\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  49401\n",
      "step = 49600: loss = 0.5456687211990356\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  49601\n",
      "step = 49800: loss = 0.25755614042282104\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  49801\n",
      "step = 50000: loss = 0.2929912507534027\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  50001\n",
      "total step is 24137\n",
      "total reward is [23707.512]\n",
      "step = 50000: Average Return = 23707.51171875\n"
     ]
    }
   ],
   "source": [
    "final_time_step, policy_state = driver.run()\n",
    "episode_len = []\n",
    "step_len = []\n",
    "losses = []\n",
    "returns = []\n",
    "# agent.train_step_counter.assign(0)\n",
    "# num_iterations = 10000\n",
    "\n",
    "for i in range(num_iterations+1):\n",
    "    # time_step, _ = driver.run(time_step)\n",
    "    final_time_step, _ = driver.run(final_time_step, policy_state)\n",
    "    \n",
    "    experience, _ = next(data_iter)\n",
    "    train_loss = agent.train(experience=experience)\n",
    "    step = agent.train_step_counter.numpy()\n",
    "\n",
    "    if step % log_interval == 0:\n",
    "        print('step = {0}: loss = {1}'.format(step, train_loss.loss))\n",
    "        episode_len.append(metrics[3].result().numpy())\n",
    "        step_len.append(step)\n",
    "        print('Average episode length: {}'.format(metrics[3].result().numpy()))\n",
    "        print('Number of Steps: ', metrics[1].result().numpy())\n",
    "    \n",
    "    if step % eval_interval == 0:\n",
    "        avg_return = compute_avg_return(eval_tf_env, agent.policy, num_eval_episodes)\n",
    "        print('step = {0}: Average Return = {1}'.format(step, avg_return))\n",
    "        losses.append(train_loss)\n",
    "        returns.append(avg_return)\n",
    "        train_checkpointer.save(global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ef0a5e-8f2f-447d-9e51-fde8a14f9b8c",
   "metadata": {},
   "source": [
    "### Load Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2bca20cd-c1b3-44c2-8908-f58b93cf142a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step is <tf.Variable 'global_step:0' shape=() dtype=int64, numpy=50000>\n",
      "num_iterations is 10000\n"
     ]
    }
   ],
   "source": [
    "num_iterations = 10000\n",
    "train_checkpointer.initialize_or_restore()\n",
    "global_step = tf.compat.v1.train.get_global_step()\n",
    "print('global step is', global_step)\n",
    "print('num_iterations is', num_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4db10783-1e77-405d-aea8-cebd1b981cb1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 80200: loss = 0.14651313424110413\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  80202\n",
      "step = 80400: loss = 0.25144684314727783\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  80402\n",
      "step = 80600: loss = 0.5044105052947998\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  80602\n",
      "step = 80800: loss = 0.3912681043148041\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  80802\n",
      "step = 81000: loss = 0.17815321683883667\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  81002\n",
      "total step is 24137\n",
      "total reward is [23521.482]\n",
      "step = 81000: Average Return = 23521.482421875\n",
      "step = 81200: loss = 0.22383493185043335\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  81202\n",
      "step = 81400: loss = 0.264889121055603\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  81402\n",
      "step = 81600: loss = 0.422145813703537\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  81602\n",
      "step = 81800: loss = 0.43516433238983154\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  81802\n",
      "step = 82000: loss = 0.2101748138666153\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  82002\n",
      "total step is 24137\n",
      "total reward is [23542.605]\n",
      "step = 82000: Average Return = 23542.60546875\n",
      "step = 82200: loss = 0.23337291181087494\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  82202\n",
      "step = 82400: loss = 0.44359472393989563\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  82402\n",
      "step = 82600: loss = 0.2318568378686905\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  82602\n",
      "step = 82800: loss = 0.26732879877090454\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  82802\n",
      "step = 83000: loss = 0.40511149168014526\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  83002\n",
      "total step is 24137\n",
      "total reward is [23523.596]\n",
      "step = 83000: Average Return = 23523.595703125\n",
      "step = 83200: loss = 0.2130066454410553\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  83202\n",
      "step = 83400: loss = 0.4689701497554779\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  83402\n",
      "step = 83600: loss = 0.4539162814617157\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  83602\n",
      "step = 83800: loss = 0.22424015402793884\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  83802\n",
      "step = 84000: loss = 0.4410032033920288\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  84002\n",
      "total step is 24137\n",
      "total reward is [23524.516]\n",
      "step = 84000: Average Return = 23524.515625\n",
      "step = 84200: loss = 0.4622229039669037\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  84202\n",
      "step = 84400: loss = 0.457053542137146\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  84402\n",
      "step = 84600: loss = 0.18027807772159576\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  84602\n",
      "step = 84800: loss = 0.24873536825180054\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  84802\n",
      "step = 85000: loss = 0.3827555775642395\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  85002\n",
      "total step is 24137\n",
      "total reward is [23534.604]\n",
      "step = 85000: Average Return = 23534.603515625\n",
      "step = 85200: loss = 0.33455610275268555\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  85202\n",
      "step = 85400: loss = 0.22852933406829834\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  85402\n",
      "step = 85600: loss = 0.5889701843261719\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  85602\n",
      "step = 85800: loss = 0.23644310235977173\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  85802\n",
      "step = 86000: loss = 0.43686237931251526\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  86002\n",
      "total step is 24137\n",
      "total reward is [23518.545]\n",
      "step = 86000: Average Return = 23518.544921875\n",
      "step = 86200: loss = 0.44353529810905457\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  86202\n",
      "step = 86400: loss = 0.25983956456184387\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  86402\n",
      "step = 86600: loss = 0.20293766260147095\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  86602\n",
      "step = 86800: loss = 0.46090957522392273\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  86802\n",
      "step = 87000: loss = 0.29004982113838196\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  87002\n",
      "total step is 24137\n",
      "total reward is [23524.762]\n",
      "step = 87000: Average Return = 23524.76171875\n",
      "step = 87200: loss = 0.4964926838874817\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  87202\n",
      "step = 87400: loss = 0.44711834192276\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  87402\n",
      "step = 87600: loss = 0.44353848695755005\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  87602\n",
      "step = 87800: loss = 0.34532180428504944\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  87802\n",
      "step = 88000: loss = 0.354810893535614\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  88002\n",
      "total step is 24137\n",
      "total reward is [23520.549]\n",
      "step = 88000: Average Return = 23520.548828125\n",
      "step = 88200: loss = 0.3956297039985657\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  88202\n",
      "step = 88400: loss = 0.5288643836975098\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  88402\n",
      "step = 88600: loss = 0.44035589694976807\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  88602\n",
      "step = 88800: loss = 0.2993595600128174\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  88802\n",
      "step = 89000: loss = 0.3258512020111084\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  89002\n",
      "total step is 24137\n",
      "total reward is [23535.248]\n",
      "step = 89000: Average Return = 23535.248046875\n",
      "step = 89200: loss = 0.5464091300964355\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  89202\n",
      "step = 89400: loss = 0.6109188199043274\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  89402\n",
      "step = 89600: loss = 0.25262582302093506\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  89602\n",
      "step = 89800: loss = 0.4203624129295349\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  89802\n",
      "step = 90000: loss = 0.20949798822402954\n",
      "Average episode length: 45576.0\n",
      "Number of Steps:  90002\n",
      "total step is 24137\n",
      "total reward is [23534.516]\n",
      "step = 90000: Average Return = 23534.515625\n"
     ]
    }
   ],
   "source": [
    "# episode_len = []\n",
    "# step_len = []\n",
    "# losses = []\n",
    "# returns = []\n",
    "# final_time_step, policy_state = driver.run()\n",
    "for i in range(num_iterations+1):\n",
    "    # time_step, _ = driver.run(time_step)\n",
    "    final_time_step, _ = driver.run(final_time_step, policy_state)\n",
    "    \n",
    "    experience, _ = next(data_iter)\n",
    "    train_loss = agent.train(experience=experience)\n",
    "    step = agent.train_step_counter.numpy()\n",
    "\n",
    "    if step % log_interval == 0:\n",
    "        print('step = {0}: loss = {1}'.format(step, train_loss.loss))\n",
    "        episode_len.append(metrics[3].result().numpy())\n",
    "        step_len.append(step)\n",
    "        print('Average episode length: {}'.format(metrics[3].result().numpy()))\n",
    "        print('Number of Steps: ', metrics[1].result().numpy())\n",
    "    \n",
    "    if step % eval_interval == 0:\n",
    "        avg_return = compute_avg_return(eval_tf_env, agent.policy, num_eval_episodes)\n",
    "        print('step = {0}: Average Return = {1}'.format(step, avg_return))\n",
    "        losses.append(train_loss)\n",
    "        returns.append(avg_return)\n",
    "        train_checkpointer.save(global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b12a91c-d0b1-4c19-b636-e8bfcd5e0977",
   "metadata": {},
   "source": [
    "### Plot Rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c05ba959-c51f-4088-a666-9d9a1f244978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.lineplot(data=returns[30:])\n",
    "# plt.xlim(10, len(returns))\n",
    "# plt.ylim(13250, max(returns)+500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290c538d-4f9b-44be-9199-0d7ba19c94bd",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cfaf48-1cbe-4997-bf8c-9e06501cf472",
   "metadata": {},
   "source": [
    "### ROCAUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0857199e-8638-460b-826c-19c5d13344f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_q_values, _ = agent._q_network(eval_data_x) \n",
    "train_q_values, _ = agent._q_network(train_data_x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d7cefa44-6c5d-4910-bdf3-7acb871220a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fpr, train_tpr, _ = roc_curve(train_data_y, train_q_values[:, 1])\n",
    "test_fpr, test_tpr, _ = roc_curve(eval_data_y, eval_q_values[:, 1])\n",
    "\n",
    "train_auc = roc_auc_score(y_train, train_q_values[:, 1])\n",
    "test_auc = roc_auc_score(y_test, eval_q_values[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6082ed14-0523-4613-b3a5-258590421afc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(train_fpr, train_tpr, color=\"b\",lw=lw, label=\"Train ROC curve (area = %0.4f)\" % train_auc)\n",
    "plt.plot(test_fpr, test_tpr, color=\"r\",lw=lw, label=\"Test ROC curve (area = %0.4f)\" % test_auc)\n",
    "plt.plot([0, 1], [0, 1], color=\"navy\", lw=lw, linestyle=\"--\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver operating characteristic example\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8dc119d-acf2-4c75-9396-e7ffca70c9c9",
   "metadata": {},
   "source": [
    "## Threshold Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bcdc8b8a-a07d-4697-b67e-af31e2f333b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_analysis(result, label_col, proba_col, tops=None):\n",
    "    if tops is None:\n",
    "        tops = [1]\n",
    "        tops.extend(np.arange(2, 6, 1))\n",
    "        tops.extend(np.arange(10, 105, 5))\n",
    "        tops = [t/100 for t in tops]\n",
    "\n",
    "    threshold_opt = pd.DataFrame()\n",
    "\n",
    "    for top in tops:\n",
    "        percentile = 1-top\n",
    "        threshold = result[proba_col].astype(float).quantile(percentile)\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(result[label_col], result[proba_col] > threshold).ravel()\n",
    "\n",
    "        precision = tp/(tp+fp)\n",
    "        recall = tp/(tp+fn)\n",
    "\n",
    "        f1 = fbeta_score(result[label_col], result[proba_col] > threshold, beta=1)\n",
    "        f2 = fbeta_score(result[label_col], result[proba_col] > threshold, beta=2)\n",
    "\n",
    "        top_idx = top*100\n",
    "        threshold_opt.loc[top_idx, 'threshold'] = threshold\n",
    "        threshold_opt.loc[top_idx, 'lead_size'] = (result[proba_col] > threshold).sum()\n",
    "        threshold_opt.loc[top_idx, 'true_positive'] = tp\n",
    "        threshold_opt.loc[top_idx, 'false_positive'] = fp\n",
    "        threshold_opt.loc[top_idx, 'true_negative'] = tn\n",
    "        threshold_opt.loc[top_idx, 'false_negative'] = fn\n",
    "        threshold_opt.loc[top_idx, 'precision'] = precision\n",
    "        threshold_opt.loc[top_idx, 'recall'] = recall\n",
    "        threshold_opt.loc[top_idx, 'f1'] = f1\n",
    "        threshold_opt.loc[top_idx, 'f2'] = f2\n",
    "\n",
    "        threshold_opt.index.name = 'top'\n",
    "\n",
    "        cols = ['lead_size', 'true_positive', 'false_positive', 'true_negative', 'false_negative']\n",
    "        threshold_opt[cols] = threshold_opt[cols].astype(int)\n",
    "    threshold_opt.reset_index(inplace=True)\n",
    "\n",
    "    return threshold_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9dee057e-50f8-4819-94a2-cf2ae57e8f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top</th>\n",
       "      <th>threshold</th>\n",
       "      <th>lead_size</th>\n",
       "      <th>true_positive</th>\n",
       "      <th>false_positive</th>\n",
       "      <th>true_negative</th>\n",
       "      <th>false_negative</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.577185</td>\n",
       "      <td>242</td>\n",
       "      <td>242</td>\n",
       "      <td>0</td>\n",
       "      <td>10148</td>\n",
       "      <td>13747</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.017299</td>\n",
       "      <td>0.034010</td>\n",
       "      <td>0.021531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.534000</td>\n",
       "      <td>483</td>\n",
       "      <td>483</td>\n",
       "      <td>0</td>\n",
       "      <td>10148</td>\n",
       "      <td>13506</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.034527</td>\n",
       "      <td>0.066750</td>\n",
       "      <td>0.042790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.510484</td>\n",
       "      <td>725</td>\n",
       "      <td>725</td>\n",
       "      <td>0</td>\n",
       "      <td>10148</td>\n",
       "      <td>13264</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.051826</td>\n",
       "      <td>0.098546</td>\n",
       "      <td>0.063954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.492962</td>\n",
       "      <td>966</td>\n",
       "      <td>966</td>\n",
       "      <td>0</td>\n",
       "      <td>10148</td>\n",
       "      <td>13023</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069054</td>\n",
       "      <td>0.129188</td>\n",
       "      <td>0.084853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.478877</td>\n",
       "      <td>1207</td>\n",
       "      <td>1207</td>\n",
       "      <td>0</td>\n",
       "      <td>10148</td>\n",
       "      <td>12782</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.086282</td>\n",
       "      <td>0.158858</td>\n",
       "      <td>0.105575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.443754</td>\n",
       "      <td>2414</td>\n",
       "      <td>2414</td>\n",
       "      <td>0</td>\n",
       "      <td>10148</td>\n",
       "      <td>11575</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.172564</td>\n",
       "      <td>0.294336</td>\n",
       "      <td>0.206784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15.0</td>\n",
       "      <td>1.419320</td>\n",
       "      <td>3621</td>\n",
       "      <td>3621</td>\n",
       "      <td>0</td>\n",
       "      <td>10148</td>\n",
       "      <td>10368</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.258846</td>\n",
       "      <td>0.411244</td>\n",
       "      <td>0.303892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20.0</td>\n",
       "      <td>1.395632</td>\n",
       "      <td>4826</td>\n",
       "      <td>4826</td>\n",
       "      <td>0</td>\n",
       "      <td>10148</td>\n",
       "      <td>9163</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.344985</td>\n",
       "      <td>0.512995</td>\n",
       "      <td>0.396993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>25.0</td>\n",
       "      <td>1.370580</td>\n",
       "      <td>6034</td>\n",
       "      <td>6034</td>\n",
       "      <td>0</td>\n",
       "      <td>10148</td>\n",
       "      <td>7955</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.431339</td>\n",
       "      <td>0.602707</td>\n",
       "      <td>0.486691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>30.0</td>\n",
       "      <td>1.344145</td>\n",
       "      <td>7241</td>\n",
       "      <td>7241</td>\n",
       "      <td>0</td>\n",
       "      <td>10148</td>\n",
       "      <td>6748</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.517621</td>\n",
       "      <td>0.682148</td>\n",
       "      <td>0.572891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>35.0</td>\n",
       "      <td>1.313711</td>\n",
       "      <td>8448</td>\n",
       "      <td>8448</td>\n",
       "      <td>0</td>\n",
       "      <td>10148</td>\n",
       "      <td>5541</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.603903</td>\n",
       "      <td>0.753042</td>\n",
       "      <td>0.655860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>40.0</td>\n",
       "      <td>1.281722</td>\n",
       "      <td>9655</td>\n",
       "      <td>9655</td>\n",
       "      <td>0</td>\n",
       "      <td>10148</td>\n",
       "      <td>4334</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.690185</td>\n",
       "      <td>0.816698</td>\n",
       "      <td>0.735776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>45.0</td>\n",
       "      <td>1.216982</td>\n",
       "      <td>10862</td>\n",
       "      <td>10862</td>\n",
       "      <td>0</td>\n",
       "      <td>10148</td>\n",
       "      <td>3127</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.776467</td>\n",
       "      <td>0.874170</td>\n",
       "      <td>0.812805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.829928</td>\n",
       "      <td>12067</td>\n",
       "      <td>11981</td>\n",
       "      <td>86</td>\n",
       "      <td>10062</td>\n",
       "      <td>2008</td>\n",
       "      <td>0.992873</td>\n",
       "      <td>0.856459</td>\n",
       "      <td>0.919635</td>\n",
       "      <td>0.880658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>55.0</td>\n",
       "      <td>-0.323347</td>\n",
       "      <td>13275</td>\n",
       "      <td>12499</td>\n",
       "      <td>776</td>\n",
       "      <td>9372</td>\n",
       "      <td>1490</td>\n",
       "      <td>0.941544</td>\n",
       "      <td>0.893488</td>\n",
       "      <td>0.916887</td>\n",
       "      <td>0.902703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>60.0</td>\n",
       "      <td>-0.452959</td>\n",
       "      <td>14482</td>\n",
       "      <td>12837</td>\n",
       "      <td>1645</td>\n",
       "      <td>8503</td>\n",
       "      <td>1152</td>\n",
       "      <td>0.886411</td>\n",
       "      <td>0.917650</td>\n",
       "      <td>0.901760</td>\n",
       "      <td>0.911227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>65.0</td>\n",
       "      <td>-0.513946</td>\n",
       "      <td>15689</td>\n",
       "      <td>13115</td>\n",
       "      <td>2574</td>\n",
       "      <td>7574</td>\n",
       "      <td>874</td>\n",
       "      <td>0.835936</td>\n",
       "      <td>0.937522</td>\n",
       "      <td>0.883820</td>\n",
       "      <td>0.915277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>70.0</td>\n",
       "      <td>-0.566021</td>\n",
       "      <td>16896</td>\n",
       "      <td>13390</td>\n",
       "      <td>3506</td>\n",
       "      <td>6642</td>\n",
       "      <td>599</td>\n",
       "      <td>0.792495</td>\n",
       "      <td>0.957181</td>\n",
       "      <td>0.867088</td>\n",
       "      <td>0.918986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>75.0</td>\n",
       "      <td>-0.619307</td>\n",
       "      <td>18102</td>\n",
       "      <td>13587</td>\n",
       "      <td>4515</td>\n",
       "      <td>5633</td>\n",
       "      <td>402</td>\n",
       "      <td>0.750580</td>\n",
       "      <td>0.971263</td>\n",
       "      <td>0.846779</td>\n",
       "      <td>0.917322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>80.0</td>\n",
       "      <td>-0.682559</td>\n",
       "      <td>19309</td>\n",
       "      <td>13734</td>\n",
       "      <td>5575</td>\n",
       "      <td>4573</td>\n",
       "      <td>255</td>\n",
       "      <td>0.711275</td>\n",
       "      <td>0.981771</td>\n",
       "      <td>0.824914</td>\n",
       "      <td>0.912376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>85.0</td>\n",
       "      <td>-0.753181</td>\n",
       "      <td>20516</td>\n",
       "      <td>13839</td>\n",
       "      <td>6677</td>\n",
       "      <td>3471</td>\n",
       "      <td>150</td>\n",
       "      <td>0.674547</td>\n",
       "      <td>0.989277</td>\n",
       "      <td>0.802145</td>\n",
       "      <td>0.904841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>90.0</td>\n",
       "      <td>-0.835854</td>\n",
       "      <td>21723</td>\n",
       "      <td>13926</td>\n",
       "      <td>7797</td>\n",
       "      <td>2351</td>\n",
       "      <td>63</td>\n",
       "      <td>0.641072</td>\n",
       "      <td>0.995496</td>\n",
       "      <td>0.779906</td>\n",
       "      <td>0.896381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>95.0</td>\n",
       "      <td>-0.935436</td>\n",
       "      <td>22923</td>\n",
       "      <td>13970</td>\n",
       "      <td>8953</td>\n",
       "      <td>1195</td>\n",
       "      <td>19</td>\n",
       "      <td>0.609432</td>\n",
       "      <td>0.998642</td>\n",
       "      <td>0.756935</td>\n",
       "      <td>0.885534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>100.0</td>\n",
       "      <td>-1.527692</td>\n",
       "      <td>24136</td>\n",
       "      <td>13989</td>\n",
       "      <td>10147</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.579591</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.733849</td>\n",
       "      <td>0.873308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      top  threshold  lead_size  true_positive  false_positive  true_negative  \\\n",
       "0     1.0   1.577185        242            242               0          10148   \n",
       "1     2.0   1.534000        483            483               0          10148   \n",
       "2     3.0   1.510484        725            725               0          10148   \n",
       "3     4.0   1.492962        966            966               0          10148   \n",
       "4     5.0   1.478877       1207           1207               0          10148   \n",
       "5    10.0   1.443754       2414           2414               0          10148   \n",
       "6    15.0   1.419320       3621           3621               0          10148   \n",
       "7    20.0   1.395632       4826           4826               0          10148   \n",
       "8    25.0   1.370580       6034           6034               0          10148   \n",
       "9    30.0   1.344145       7241           7241               0          10148   \n",
       "10   35.0   1.313711       8448           8448               0          10148   \n",
       "11   40.0   1.281722       9655           9655               0          10148   \n",
       "12   45.0   1.216982      10862          10862               0          10148   \n",
       "13   50.0   0.829928      12067          11981              86          10062   \n",
       "14   55.0  -0.323347      13275          12499             776           9372   \n",
       "15   60.0  -0.452959      14482          12837            1645           8503   \n",
       "16   65.0  -0.513946      15689          13115            2574           7574   \n",
       "17   70.0  -0.566021      16896          13390            3506           6642   \n",
       "18   75.0  -0.619307      18102          13587            4515           5633   \n",
       "19   80.0  -0.682559      19309          13734            5575           4573   \n",
       "20   85.0  -0.753181      20516          13839            6677           3471   \n",
       "21   90.0  -0.835854      21723          13926            7797           2351   \n",
       "22   95.0  -0.935436      22923          13970            8953           1195   \n",
       "23  100.0  -1.527692      24136          13989           10147              1   \n",
       "\n",
       "    false_negative  precision    recall        f1        f2  \n",
       "0            13747   1.000000  0.017299  0.034010  0.021531  \n",
       "1            13506   1.000000  0.034527  0.066750  0.042790  \n",
       "2            13264   1.000000  0.051826  0.098546  0.063954  \n",
       "3            13023   1.000000  0.069054  0.129188  0.084853  \n",
       "4            12782   1.000000  0.086282  0.158858  0.105575  \n",
       "5            11575   1.000000  0.172564  0.294336  0.206784  \n",
       "6            10368   1.000000  0.258846  0.411244  0.303892  \n",
       "7             9163   1.000000  0.344985  0.512995  0.396993  \n",
       "8             7955   1.000000  0.431339  0.602707  0.486691  \n",
       "9             6748   1.000000  0.517621  0.682148  0.572891  \n",
       "10            5541   1.000000  0.603903  0.753042  0.655860  \n",
       "11            4334   1.000000  0.690185  0.816698  0.735776  \n",
       "12            3127   1.000000  0.776467  0.874170  0.812805  \n",
       "13            2008   0.992873  0.856459  0.919635  0.880658  \n",
       "14            1490   0.941544  0.893488  0.916887  0.902703  \n",
       "15            1152   0.886411  0.917650  0.901760  0.911227  \n",
       "16             874   0.835936  0.937522  0.883820  0.915277  \n",
       "17             599   0.792495  0.957181  0.867088  0.918986  \n",
       "18             402   0.750580  0.971263  0.846779  0.917322  \n",
       "19             255   0.711275  0.981771  0.824914  0.912376  \n",
       "20             150   0.674547  0.989277  0.802145  0.904841  \n",
       "21              63   0.641072  0.995496  0.779906  0.896381  \n",
       "22              19   0.609432  0.998642  0.756935  0.885534  \n",
       "23               0   0.579591  1.000000  0.733849  0.873308  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_score = eval_q_values[:, 1].numpy()\n",
    "eval_df = pd.DataFrame({'y_true': y_test, 'y_pred': y_test_score})\n",
    "threshold_analysis(eval_df, 'y_true', 'y_pred', tops=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "95b993b1-1dd0-4a80-b9b5-0576efdaa8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 1.216982\n",
    "test_df['predict'] = np.where(y_test_score >= threshold, 1, 0)\n",
    "test_df['predicted_reward'] = y_test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7345191c-9d65-4bb8-8aca-c9ba25e34aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Apply</th>\n",
       "      <th>Loan_Amount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predict</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13275</td>\n",
       "      <td>3127</td>\n",
       "      <td>113171000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10862</td>\n",
       "      <td>10862</td>\n",
       "      <td>443795000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID  Apply  Loan_Amount\n",
       "predict                           \n",
       "0        13275   3127  113171000.0\n",
       "1        10862  10862  443795000.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.groupby('predict').agg({\n",
    "    'ID': 'count',\n",
    "    'Apply': 'sum',\n",
    "    'Loan_Amount': 'sum'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f820e736-0adf-4765-8b6c-ed4f6fa47356",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_cumsum(result, label_col, proba_col, cumsum_col, tops=None):\n",
    "    if tops is None:\n",
    "        tops = [1]\n",
    "        tops.extend(np.arange(2, 6, 1))\n",
    "        tops.extend(np.arange(10, 105, 5))\n",
    "        tops = [t/100 for t in tops]\n",
    "\n",
    "    threshold_opt = pd.DataFrame()\n",
    "\n",
    "    for top in tops:\n",
    "        percentile = 1-top\n",
    "        threshold = result[proba_col].astype(float).quantile(percentile)\n",
    "\n",
    "        top_idx = top*100\n",
    "        threshold_opt.loc[top_idx, 'threshold'] = threshold\n",
    "        threshold_opt.loc[top_idx, 'lead_size'] = (result[proba_col] >= threshold).sum()\n",
    "        threshold_opt.loc[top_idx, 'cumsum_loan_amount'] = result[result[proba_col]>=threshold][cumsum_col].sum()\n",
    "\n",
    "        threshold_opt.index.name = 'top'\n",
    "\n",
    "        cols = ['lead_size', 'cumsum_loan_amount']\n",
    "        threshold_opt[cols] = threshold_opt[cols].astype(int)\n",
    "    threshold_opt.reset_index(inplace=True)\n",
    "\n",
    "    return threshold_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d74f4e05-a13e-43ba-8ef9-c8428afdcf38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top</th>\n",
       "      <th>threshold</th>\n",
       "      <th>lead_size</th>\n",
       "      <th>cumsum_loan_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.577185</td>\n",
       "      <td>242</td>\n",
       "      <td>16220000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.534000</td>\n",
       "      <td>483</td>\n",
       "      <td>30078000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.510484</td>\n",
       "      <td>725</td>\n",
       "      <td>43963000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.492962</td>\n",
       "      <td>966</td>\n",
       "      <td>56225000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.478877</td>\n",
       "      <td>1207</td>\n",
       "      <td>68872000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.443754</td>\n",
       "      <td>2414</td>\n",
       "      <td>128563000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15.0</td>\n",
       "      <td>1.419320</td>\n",
       "      <td>3621</td>\n",
       "      <td>181297000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20.0</td>\n",
       "      <td>1.395632</td>\n",
       "      <td>4829</td>\n",
       "      <td>230818000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>25.0</td>\n",
       "      <td>1.370580</td>\n",
       "      <td>6035</td>\n",
       "      <td>277243000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>30.0</td>\n",
       "      <td>1.344145</td>\n",
       "      <td>7241</td>\n",
       "      <td>321261000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>35.0</td>\n",
       "      <td>1.313711</td>\n",
       "      <td>8448</td>\n",
       "      <td>366547000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>40.0</td>\n",
       "      <td>1.281722</td>\n",
       "      <td>9655</td>\n",
       "      <td>405638000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>45.0</td>\n",
       "      <td>1.216982</td>\n",
       "      <td>10862</td>\n",
       "      <td>443795000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.829928</td>\n",
       "      <td>12070</td>\n",
       "      <td>478319000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>55.0</td>\n",
       "      <td>-0.323347</td>\n",
       "      <td>13275</td>\n",
       "      <td>502851000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>60.0</td>\n",
       "      <td>-0.452959</td>\n",
       "      <td>14482</td>\n",
       "      <td>516567000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>65.0</td>\n",
       "      <td>-0.513946</td>\n",
       "      <td>15689</td>\n",
       "      <td>527447000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>70.0</td>\n",
       "      <td>-0.566021</td>\n",
       "      <td>16896</td>\n",
       "      <td>536891000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>75.0</td>\n",
       "      <td>-0.619307</td>\n",
       "      <td>18103</td>\n",
       "      <td>543182000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>80.0</td>\n",
       "      <td>-0.682559</td>\n",
       "      <td>19309</td>\n",
       "      <td>548051000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>85.0</td>\n",
       "      <td>-0.753181</td>\n",
       "      <td>20516</td>\n",
       "      <td>551821000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>90.0</td>\n",
       "      <td>-0.835854</td>\n",
       "      <td>21723</td>\n",
       "      <td>554869000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>95.0</td>\n",
       "      <td>-0.935436</td>\n",
       "      <td>22939</td>\n",
       "      <td>556064000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>100.0</td>\n",
       "      <td>-1.527692</td>\n",
       "      <td>24137</td>\n",
       "      <td>556966000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      top  threshold  lead_size  cumsum_loan_amount\n",
       "0     1.0   1.577185        242            16220000\n",
       "1     2.0   1.534000        483            30078000\n",
       "2     3.0   1.510484        725            43963000\n",
       "3     4.0   1.492962        966            56225000\n",
       "4     5.0   1.478877       1207            68872000\n",
       "5    10.0   1.443754       2414           128563000\n",
       "6    15.0   1.419320       3621           181297000\n",
       "7    20.0   1.395632       4829           230818000\n",
       "8    25.0   1.370580       6035           277243000\n",
       "9    30.0   1.344145       7241           321261000\n",
       "10   35.0   1.313711       8448           366547000\n",
       "11   40.0   1.281722       9655           405638000\n",
       "12   45.0   1.216982      10862           443795000\n",
       "13   50.0   0.829928      12070           478319000\n",
       "14   55.0  -0.323347      13275           502851000\n",
       "15   60.0  -0.452959      14482           516567000\n",
       "16   65.0  -0.513946      15689           527447000\n",
       "17   70.0  -0.566021      16896           536891000\n",
       "18   75.0  -0.619307      18103           543182000\n",
       "19   80.0  -0.682559      19309           548051000\n",
       "20   85.0  -0.753181      20516           551821000\n",
       "21   90.0  -0.835854      21723           554869000\n",
       "22   95.0  -0.935436      22939           556064000\n",
       "23  100.0  -1.527692      24137           556966000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward_cumsum(test_df, label_col='Apply', proba_col='predicted_reward', cumsum_col='Loan_Amount', tops=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692768ed-9d7b-43a0-af0f-cd21613bc6c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtualENV",
   "language": "python",
   "name": "virtualenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}