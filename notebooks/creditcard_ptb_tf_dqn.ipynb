{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0deb761b-3d9b-4ed2-b04e-7a933dd0b680",
   "metadata": {},
   "source": [
    "# Credit Card PTB by TF Agent DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b88042bb-949c-4b77-90c0-e5030f416ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "curr_folder = globals()['_dh']\n",
    "\n",
    "os.chdir(os.path.join(curr_folder[0], '..'))\n",
    "sys.path.append(os.path.join(curr_folder[0], '..'))\n",
    "sys.path.append(os.path.join(curr_folder[0], '../marketing_rl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1ccfacc-6730-488d-891f-e993fae9187b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tf_agents.agents.dqn import dqn_agent\n",
    "from tf_agents.drivers import dynamic_step_driver\n",
    "from tf_agents.networks.q_network import QNetwork\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.replay_buffers import TFUniformReplayBuffer\n",
    "from tf_agents.utils.common import element_wise_squared_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from marketing_rl.environment.biclass_tf_env import BiClassTFEnv, EnvMode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1cfaa6-2531-4d05-ac65-63ca7a9ddf03",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4eb3588-03e1-4887-ad36-4607e885bda2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data size is 245725\n"
     ]
    }
   ],
   "source": [
    "data_path = 'data/Credit Card Lead Prediction Dataset/train_s3TEQDk.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "print('total data size is', df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aaeec99-a129-4f7f-824b-ca1780199085",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1a68cd-2de0-4bd3-a3aa-3f2ee32febb7",
   "metadata": {},
   "source": [
    "### Prep Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55b6c298-df9c-4c6d-bba2-846ed4c32587",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_col = 'Is_Lead'\n",
    "index_col = 'ID'\n",
    "feat_cols = ['Gender', 'Age', 'Region_Code', 'Occupation', 'Channel_Code',\n",
    "             'Vintage', 'Credit_Product', 'Avg_Account_Balance', 'Is_Active']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bad7e5dc-fc60-413c-91b0-84e1ee661f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size is 172007\n",
      "test size is 73718\n",
      "train positive 40818, train negative 131189\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[feat_cols], df[label_col], random_state=0, test_size=0.3, shuffle=True)\n",
    "print('train size is', X_train.shape[0])\n",
    "print('test size is', X_test.shape[0])\n",
    "print('train positive {}, train negative {}'.format(sum(y_train==1),sum(y_train==0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "017526cc-5319-4c17-8c32-e0c3221d348e",
   "metadata": {},
   "outputs": [],
   "source": [
    "numer_feats = ['Age', 'Vintage', 'Avg_Account_Balance']\n",
    "numer_transformer = StandardScaler()\n",
    "\n",
    "\n",
    "binary_feats = ['Is_Active', 'Credit_Product']\n",
    "binary_transformer = Pipeline(\n",
    "    steps=[(\"imputer\", SimpleImputer(strategy=\"constant\", fill_value='No')), (\"ordinal\", OrdinalEncoder())]\n",
    ")\n",
    "\n",
    "cat_feats = ['Gender', 'Region_Code', 'Occupation', 'Channel_Code']\n",
    "cat_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numer_transformer, numer_feats),\n",
    "        (\"ordinal\", binary_transformer, binary_feats),\n",
    "        (\"cat\", cat_transformer, cat_feats)\n",
    "    ], sparse_threshold = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1b14475-954f-490f-b1b2-5a76755cd6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_t = transformer.fit_transform(X_train)\n",
    "X_test_t = transformer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0c66104-a6e4-4561-ac85-a2259fd0aabf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] positive sample to negative sample is 0.3111388912180137\n"
     ]
    }
   ],
   "source": [
    "pos_neg_ratio = sum(y_train==1)/sum(y_train==0)\n",
    "print('[train] positive sample to negative sample is', pos_neg_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dd9680-e29a-414b-9ab5-7711a39c5bf9",
   "metadata": {},
   "source": [
    "### Prep Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd1a9ebc-ce2e-472c-9d0a-0c4b72f2cfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_x = np.array(X_train_t)\n",
    "train_data_y = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "eca18079-df42-4045-92f9-3db18c57d973",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_env = BiClassTFEnv(data_x=train_data_x, data_y=train_data_y, pos_neg_ratio=pos_neg_ratio, early_stop=10)\n",
    "train_tf_env = tf_py_environment.TFPyEnvironment(train_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e34678a-0d15-46de-836a-7cd0c4448391",
   "metadata": {},
   "source": [
    "## Agent Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "24dd957b-847a-46a1-bae8-ef06e120064e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameters\n",
    "fc_layers = (64,)\n",
    "learning_rate = 1e-5\n",
    "batch_size = 128\n",
    "\n",
    "num_iterations = 10000\n",
    "\n",
    "log_interval = 200\n",
    "eval_interval = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d6ffd703-7426-4343-bf8e-400469678985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# q network\n",
    "q_net = QNetwork(\n",
    "    input_tensor_spec = train_tf_env.observation_spec(),\n",
    "    action_spec = train_tf_env.action_spec(),\n",
    "    fc_layer_params = fc_layers,\n",
    ")\n",
    "\n",
    "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_step_counter = tf.compat.v2.Variable(0)\n",
    "\n",
    "# dqn agent\n",
    "agent = dqn_agent.DqnAgent(\n",
    "    time_step_spec = train_tf_env.time_step_spec(),\n",
    "    action_spec = train_tf_env.action_spec(),\n",
    "    q_network = q_net,\n",
    "    optimizer = optimizer,\n",
    "    td_errors_loss_fn = element_wise_squared_loss,\n",
    "    train_step_counter = train_step_counter,\n",
    ")\n",
    "agent.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1848d0-a835-4762-b38e-6b5db2daf286",
   "metadata": {},
   "source": [
    "## Agent Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2a7e179c-0629-4cd5-876c-28015455097b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size: None\n"
     ]
    }
   ],
   "source": [
    "# initiate replay buffer for training\n",
    "replay_buffer = TFUniformReplayBuffer(\n",
    "    data_spec = agent.collect_data_spec,\n",
    "    batch_size = train_tf_env.batch_size,\n",
    ")\n",
    "print(\"Batch Size: {}\".format(train_env.batch_size))\n",
    "\n",
    "replay_observer = [replay_buffer.add_batch]\n",
    "\n",
    "# policy\n",
    "eval_policy = agent.policy\n",
    "collect_policy = agent.collect_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4d183343-19cc-497a-82c1-c9476d63e69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = replay_buffer.as_dataset(\n",
    "    num_parallel_calls = 3, \n",
    "    sample_batch_size = batch_size,\n",
    "    num_steps = 2\n",
    ").prefetch(3)\n",
    "\n",
    "date_iter = iter(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "93f257cc-b5b7-4988-8eea-b8c576eec091",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    tf_metrics.NumberOfEpisodes(),\n",
    "    tf_metrics.EnvironmentSteps(),\n",
    "    tf_metrics.AverageReturnMetric(),\n",
    "    tf_metrics.AverageEpisodeLengthMetric(),\n",
    "    \n",
    "]\n",
    "\n",
    "driver = dynamic_step_driver.DynamicStepDriver(\n",
    "    env = train_tf_env,\n",
    "    policy = collect_policy,\n",
    "    observers = replay_observer + metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a8579732-5cb7-4b1f-9d01-cba3610248f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_avg_return(environment, policy, num_episodes=10):\n",
    "    print('computing average return for {} episodes'.format(num_episodes))\n",
    "    total_return = 0.0\n",
    "    for i in range(num_episodes):\n",
    "        print(f'episode {i}')\n",
    "        time_step = environment.reset()\n",
    "        episode_return = 0.0\n",
    "\n",
    "        while not time_step.is_last():\n",
    "            action_step = policy.action(time_step)\n",
    "            time_step = environment.step(action_step.action)\n",
    "            episode_return += time_step.reward\n",
    "            total_return += episode_return\n",
    "\n",
    "    avg_return = total_return / num_episodes\n",
    "    return avg_return.numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "07a04c08-0bd5-4632-ad2c-875e26b38ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data_x = np.array(X_test_t)\n",
    "eval_data_y = np.array(y_test)\n",
    "\n",
    "eval_env = BiClassTFEnv(data_x=eval_data_x, data_y=eval_data_y, pos_neg_ratio=pos_neg_ratio, mode=EnvMode.TEST)\n",
    "eval_tf_env = tf_py_environment.TFPyEnvironment(eval_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4e0b7706-3d04-43ff-a049-5bf3f030cc12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 200: loss = 0.3271228075027466\n",
      "Average episode length: 190.0\n",
      "step = 400: loss = 0.35739457607269287\n",
      "Average episode length: 276.0\n",
      "step = 600: loss = 0.3588135242462158\n",
      "Average episode length: 256.0\n",
      "step = 800: loss = 0.35346686840057373\n",
      "Average episode length: 198.0\n",
      "step = 1000: loss = 0.31780490279197693\n",
      "Average episode length: 188.0\n",
      "computing average return for 1 episodes\n",
      "episode 0\n",
      "step = 1000: Average Return = 387786528.0\n"
     ]
    }
   ],
   "source": [
    "num_eval_episodes = 1\n",
    "\n",
    "agent.train_step_counter.assign(0)\n",
    "episode_len, step_len = [], []\n",
    "\n",
    "final_time_step, policy_state = driver.run()\n",
    "\n",
    "for i in range(num_iterations):\n",
    "    final_time_step, _ = driver.run(final_time_step, policy_state)\n",
    "    experience, _ = next(date_iter)\n",
    "    \n",
    "    train_loss = agent.train(experience=experience)\n",
    "    step = agent.train_step_counter.numpy()\n",
    "    \n",
    "    if step % log_interval == 0:\n",
    "        print('step = {0}: loss = {1}'.format(step, train_loss.loss))\n",
    "        episode_len.append(metrics[3].result().numpy())\n",
    "        step_len.append(step)\n",
    "        print('Average episode length: {}'.format(metrics[3].result().numpy()))\n",
    "        \n",
    "    if step % eval_interval == 0:\n",
    "        avg_return = compute_avg_return(eval_tf_env, agent.policy, num_eval_episodes)\n",
    "        print('step = {0}: Average Return = {1}'.format(step, avg_return))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00100e75-3703-4424-92bf-8ec3dc51e113",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c9bb28ff-1904-48e2-b41e-8516d21d99af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing average return for 3 episodes\n",
      "episode 0\n",
      "episode 1\n",
      "episode 2\n",
      "20500766.0\n"
     ]
    }
   ],
   "source": [
    "avg_return = compute_avg_return(eval_tf_env, agent.policy, num_eval_episodes)\n",
    "print(avg_return)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mar_rl",
   "language": "python",
   "name": "mar_rl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
