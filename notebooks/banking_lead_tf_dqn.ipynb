{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb7c9b56-0b9d-48e6-9ad0-912fa10ff547",
   "metadata": {},
   "source": [
    "# DQN Model with Flexible Reward Environment for Banking Lead Conversion Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ba103a1-77f6-4252-97b2-24830f287726",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "curr_folder = globals()['_dh']\n",
    "\n",
    "os.chdir(os.path.join(curr_folder[0], '..'))\n",
    "sys.path.append(os.path.join(curr_folder[0], '..'))\n",
    "sys.path.append(os.path.join(curr_folder[0], '../marketing_rl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d7d6cc2-7949-4225-a6e8-677331659eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report, roc_curve, roc_auc_score, auc, confusion_matrix, fbeta_score\n",
    "\n",
    "import tensorflow as tf\n",
    "import tf_agents.utils.common as common\n",
    "from tf_agents.agents.dqn import dqn_agent\n",
    "from tf_agents.drivers import dynamic_step_driver\n",
    "from tf_agents.networks.q_network import QNetwork\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.replay_buffers import TFUniformReplayBuffer\n",
    "\n",
    "from marketing_rl.environment.flexi_biclass_tf_env import FlexiBiClassTFEnv, EnvMode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04e376e-d1d5-49e2-bcbd-4b3c9a63547e",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "990b942e-6320-485b-8033-36d232a912da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data size is 69713\n"
     ]
    }
   ],
   "source": [
    "data_path = 'data/Banking | Marketing | Leads Conversion Data/train_loan/train.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "print('total data size is', df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45a9ec7-6509-4b4c-a90a-8e41ee2feb87",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f16f2c32-0a97-48ec-9df5-f9e375de1e1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6025275056302268"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['DOB'] = df['DOB'].apply(pd.to_datetime)\n",
    "df['Lead_Creation_Date'] = df['Lead_Creation_Date'].apply(pd.to_datetime)\n",
    "df['Age'] = (df['Lead_Creation_Date'] - df['DOB'])/ np.timedelta64(1, 'Y')\n",
    "df['Age'] = np.where(df['Age'] < 0, np.nan, df['Age'])\n",
    "df['Apply'] = np.where(df['Loan_Amount']>0, 1, 0)\n",
    "df['Apply'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8334307-f8f9-4a1b-aa3a-8a7cc3abf73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_col = 'Apply'\n",
    "index_col = 'ID'\n",
    "date_col = 'Lead_Creation_Date'\n",
    "feat_cols = ['Gender', 'Age', 'City_Category', 'Employer_Category1', 'Employer_Category2', \n",
    "             'Monthly_Income', 'Primary_Bank_Type',\n",
    "             'Source_Category', 'Existing_EMI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b848852-bfc2-48e9-acde-b159fdf9e653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size is 45576\n",
      "test size is 24137\n"
     ]
    }
   ],
   "source": [
    "test_cond = df['Lead_Creation_Date'] > '2016-09-01'\n",
    "train_df = df.loc[~test_cond, :].copy()\n",
    "test_df = df.loc[test_cond, :].copy()\n",
    "print('train size is', train_df.shape[0])\n",
    "print('test size is', test_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d98a2115-9997-44e7-a3d7-279d266c5e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size is 45576\n",
      "test size is 24137\n"
     ]
    }
   ],
   "source": [
    "X_train = train_df[feat_cols]\n",
    "y_train = train_df[label_col]\n",
    "X_test = test_df[feat_cols]\n",
    "y_test = test_df[label_col]\n",
    "print('train size is', X_train.shape[0])\n",
    "print('test size is', X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c639a54d-5b4b-4da7-a032-721bdba6bd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "numer_feats = ['Age', 'Monthly_Income', 'Existing_EMI']\n",
    "numer_transformer = Pipeline(\n",
    "    steps=[(\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", StandardScaler())]\n",
    ")\n",
    "\n",
    "cat_feats = ['Gender', 'City_Category', 'Employer_Category1', 'Employer_Category2', \n",
    "             'Primary_Bank_Type', 'Source_Category']\n",
    "cat_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numer_transformer, numer_feats),\n",
    "        # (\"ordinal\", binary_transformer, binary_feats),\n",
    "        (\"cat\", cat_transformer, cat_feats)\n",
    "    ], sparse_threshold = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4239089-7068-4fb8-b8c3-00f3053a2dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_t = transformer.fit_transform(X_train)\n",
    "X_test_t = transformer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c81d4817-3a74-44bb-b27a-02d9a78462e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers = transformer.get_params()['transformers']\n",
    "feature_names = []\n",
    "for name, _, features in transformers:\n",
    "    try:\n",
    "        Var = transformer.named_transformers_[name].get_feature_names().tolist()\n",
    "    except AttributeError:\n",
    "        Var = features\n",
    "    feature_names = feature_names + Var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70be69ee-59d8-44e6-9882-685bcb6cf9cd",
   "metadata": {},
   "source": [
    "## Prep Agents Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "04ef89bc-bb59-489f-b4ef-934c4c65f949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] positive sample to negative sample is 1.595296395421673\n"
     ]
    }
   ],
   "source": [
    "pos_neg_ratio = sum(y_train==1)/sum(y_train==0)\n",
    "print('[train] positive sample to negative sample is', pos_neg_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5974277f-fe4c-41c4-8ec7-d2386f92944c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] early stop is 22788.0\n"
     ]
    }
   ],
   "source": [
    "early_stop = train_df.shape[0] * 0.5\n",
    "print(f'[train] early stop is {early_stop}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c74cc566-c069-485f-9306-82fb6309d68b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     28015.000000\n",
       "mean      39237.943959\n",
       "std       30192.645464\n",
       "min        5000.000000\n",
       "25%       20000.000000\n",
       "50%       30000.000000\n",
       "75%       50000.000000\n",
       "max      300000.000000\n",
       "Name: Loan_Amount, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Loan_Amount'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff44e086-2964-4a9e-9a72-b77170f69d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(value, min_val, max_val):\n",
    "    new_value = (value -  min_val)/(max_val - min_val)\n",
    "    return new_value\n",
    "train_df['add_reward'] = train_df['Loan_Amount'].apply(lambda x: normalize_data(x, 5000, 100000))\n",
    "train_df.fillna(0, inplace=True)\n",
    "train_df['add_reward'] = train_df['add_reward'].clip(0, 1)\n",
    "\n",
    "test_df['add_reward'] = test_df['Loan_Amount'].apply(lambda x: normalize_data(x, 5000, 100000))\n",
    "test_df.fillna(0, inplace=True)\n",
    "test_df['add_reward'] = test_df['add_reward'].clip(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e08c5e68-b2b2-4b07-af2c-f79483b8e7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_x = np.array(X_train_t)\n",
    "train_data_y = np.array(y_train)\n",
    "reward = np.array(train_df['add_reward'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff72a0cc-08b2-44cb-b515-dfd56cd28a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_env = FlexiBiClassTFEnv(data_x=train_data_x, data_y=train_data_y, pos_neg_ratio=1, \n",
    "                              discount=0.1, reward=reward, early_stop=None)\n",
    "train_tf_env = tf_py_environment.TFPyEnvironment(train_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58c6f240-c516-47fb-9c00-a949e3d1a706",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data_x = np.array(X_test_t)\n",
    "eval_data_y = np.array(y_test)\n",
    "eval_reward = np.array(test_df['add_reward'])\n",
    "\n",
    "eval_env = FlexiBiClassTFEnv(data_x=eval_data_x, data_y=eval_data_y, reward=eval_reward, \n",
    "                        pos_neg_ratio=1, mode=EnvMode.TEST)\n",
    "eval_tf_env = tf_py_environment.TFPyEnvironment(eval_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4d320d-28d8-4a06-8c71-f8092e85d9e6",
   "metadata": {},
   "source": [
    "## Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991156f5-6c80-4b58-98fc-5cb5091d2800",
   "metadata": {},
   "source": [
    "### Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5eff2fe-23d6-4533-8c61-b62892d7897e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameters\n",
    "fc_layers = (64,)\n",
    "learning_rate = 1e-5\n",
    "batch_size = 64\n",
    "replay_buffer_capacity = 100000\n",
    "\n",
    "num_iterations = 20000\n",
    "num_eval_episodes = 1\n",
    "\n",
    "log_interval = 200\n",
    "eval_interval = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401cbe00-0b95-4857-8ea8-69e4d829edcb",
   "metadata": {},
   "source": [
    "### Set Q-network and initialize agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8cd8b570-d2e7-49bf-b0df-b670f27c00cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-02 15:25:40.161908: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# q network\n",
    "q_net = QNetwork(\n",
    "    input_tensor_spec = train_tf_env.observation_spec(),\n",
    "    action_spec = train_tf_env.action_spec(),\n",
    "    fc_layer_params = fc_layers,\n",
    ")\n",
    "\n",
    "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_step_counter = tf.compat.v2.Variable(0)\n",
    "# global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "# dqn agent\n",
    "agent = dqn_agent.DqnAgent(\n",
    "    time_step_spec = train_tf_env.time_step_spec(),\n",
    "    action_spec = train_tf_env.action_spec(),\n",
    "    q_network = q_net,\n",
    "    optimizer = optimizer,\n",
    "    td_errors_loss_fn = common.element_wise_squared_loss,\n",
    "    train_step_counter = train_step_counter,\n",
    "    emit_log_probability = True\n",
    ")\n",
    "agent.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96f3438-54ab-417d-b80f-5aead5241f87",
   "metadata": {},
   "source": [
    "### Train agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8decdd0-20a9-424a-adc8-d2e2186e95df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size: None\n"
     ]
    }
   ],
   "source": [
    "# initiate replay buffer for training\n",
    "replay_buffer = TFUniformReplayBuffer(\n",
    "    data_spec = agent.collect_data_spec,\n",
    "    batch_size = train_tf_env.batch_size,\n",
    "    max_length = replay_buffer_capacity,\n",
    ")\n",
    "print(\"Batch Size: {}\".format(train_env.batch_size))\n",
    "\n",
    "replay_observer = [replay_buffer.add_batch]\n",
    "metrics = [\n",
    "    tf_metrics.NumberOfEpisodes(),\n",
    "    tf_metrics.EnvironmentSteps(),\n",
    "    tf_metrics.AverageReturnMetric(),\n",
    "    tf_metrics.AverageEpisodeLengthMetric(),\n",
    "    \n",
    "]\n",
    "\n",
    "# policy\n",
    "eval_policy = agent.policy\n",
    "collect_policy = agent.collect_policy\n",
    "\n",
    "agent.train = common.function(agent.train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "313bb481-e000-41ab-9f32-1b40703b6ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/sukhumarn.a/Documents/Data Science/RL for Marketing/notebooks/virtualENV/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:377: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `as_dataset(..., single_deterministic_pass=False) instead.\n"
     ]
    }
   ],
   "source": [
    "dataset = replay_buffer.as_dataset(\n",
    "    num_parallel_calls = 3, \n",
    "    sample_batch_size = batch_size,\n",
    "    num_steps = 2\n",
    ").prefetch(3)\n",
    "\n",
    "driver = dynamic_step_driver.DynamicStepDriver(\n",
    "    env = train_tf_env,\n",
    "    policy = collect_policy,\n",
    "    observers = replay_observer + metrics,\n",
    ")\n",
    "\n",
    "data_iter = iter(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa06940e-9b5b-4fea-b20b-a2182747afc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_avg_return(environment, policy, num_episodes=1):\n",
    "    total_return = 0.0\n",
    "    total_step = 0\n",
    "    for i in range(num_episodes):\n",
    "        time_step = environment.reset()\n",
    "        episode_return = 0.0\n",
    "\n",
    "        while not time_step.is_last():\n",
    "            action_step = policy.action(time_step)\n",
    "            time_step = environment.step(action_step.action)\n",
    "            episode_return += time_step.reward\n",
    "            total_step += 1\n",
    "        total_return += episode_return\n",
    "            \n",
    "    print(f'total step is {total_step}')\n",
    "    print(f'total reward is {total_return}')\n",
    "    avg_return = total_return / num_episodes\n",
    "    return avg_return.numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7216fc10-b81b-4b56-8157-a6026e185a1e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/sukhumarn.a/Documents/Data Science/RL for Marketing/notebooks/virtualENV/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: calling foldr_v2 (from tensorflow.python.ops.functional_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.foldr(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.foldr(fn, elems))\n",
      "step = 200: loss = 0.6319252252578735\n",
      "Average episode length: 0.0\n",
      "step = 400: loss = 0.6016260385513306\n",
      "Average episode length: 0.0\n",
      "step = 600: loss = 0.5583655834197998\n",
      "Average episode length: 0.0\n",
      "step = 800: loss = 0.47366034984588623\n",
      "Average episode length: 0.0\n",
      "step = 1000: loss = 0.5307485461235046\n",
      "Average episode length: 0.0\n",
      "total step is 24137\n",
      "total reward is [5547.311]\n",
      "step = 1000: Average Return = 5547.31103515625\n",
      "step = 1200: loss = 0.5150414705276489\n",
      "Average episode length: 0.0\n",
      "step = 1400: loss = 0.3704887330532074\n",
      "Average episode length: 0.0\n",
      "step = 1600: loss = 0.3908330202102661\n",
      "Average episode length: 0.0\n",
      "step = 1800: loss = 0.41268378496170044\n",
      "Average episode length: 0.0\n",
      "step = 2000: loss = 0.4083172082901001\n",
      "Average episode length: 0.0\n",
      "total step is 24137\n",
      "total reward is [5310.101]\n",
      "step = 2000: Average Return = 5310.10107421875\n",
      "step = 2200: loss = 0.3708064556121826\n",
      "Average episode length: 0.0\n",
      "step = 2400: loss = 0.4219026565551758\n",
      "Average episode length: 0.0\n",
      "step = 2600: loss = 0.3036997318267822\n",
      "Average episode length: 0.0\n",
      "step = 2800: loss = 0.33237355947494507\n",
      "Average episode length: 0.0\n",
      "step = 3000: loss = 0.4031570553779602\n",
      "Average episode length: 0.0\n",
      "total step is 24137\n",
      "total reward is [5406.435]\n",
      "step = 3000: Average Return = 5406.43505859375\n",
      "step = 3200: loss = 0.35848164558410645\n",
      "Average episode length: 0.0\n",
      "step = 3400: loss = 0.3826741576194763\n",
      "Average episode length: 0.0\n",
      "step = 3600: loss = 0.36680281162261963\n",
      "Average episode length: 0.0\n",
      "step = 3800: loss = 0.22397488355636597\n",
      "Average episode length: 0.0\n",
      "step = 4000: loss = 0.2974568009376526\n",
      "Average episode length: 0.0\n",
      "total step is 24137\n",
      "total reward is [6051.3555]\n",
      "step = 4000: Average Return = 6051.35546875\n",
      "step = 4200: loss = 0.31393420696258545\n",
      "Average episode length: 0.0\n",
      "step = 4400: loss = 0.24180132150650024\n",
      "Average episode length: 0.0\n",
      "step = 4600: loss = 0.2540586590766907\n",
      "Average episode length: 0.0\n",
      "step = 4800: loss = 0.27967286109924316\n",
      "Average episode length: 0.0\n",
      "step = 5000: loss = 0.24734318256378174\n",
      "Average episode length: 0.0\n",
      "total step is 24137\n",
      "total reward is [6853.692]\n",
      "step = 5000: Average Return = 6853.69189453125\n",
      "step = 5200: loss = 0.3185262680053711\n",
      "Average episode length: 0.0\n",
      "step = 5400: loss = 0.16819775104522705\n",
      "Average episode length: 0.0\n",
      "step = 5600: loss = 0.19772769510746002\n",
      "Average episode length: 0.0\n",
      "step = 5800: loss = 0.33154162764549255\n",
      "Average episode length: 0.0\n",
      "step = 6000: loss = 0.23893681168556213\n",
      "Average episode length: 0.0\n",
      "total step is 24137\n",
      "total reward is [8616.802]\n",
      "step = 6000: Average Return = 8616.8017578125\n",
      "step = 6200: loss = 0.28014618158340454\n",
      "Average episode length: 0.0\n",
      "step = 6400: loss = 0.22257661819458008\n",
      "Average episode length: 0.0\n",
      "step = 6600: loss = 0.20962581038475037\n",
      "Average episode length: 0.0\n",
      "step = 6800: loss = 0.1869175285100937\n",
      "Average episode length: 0.0\n",
      "step = 7000: loss = 0.28824469447135925\n",
      "Average episode length: 0.0\n",
      "total step is 24137\n",
      "total reward is [11283.424]\n",
      "step = 7000: Average Return = 11283.423828125\n",
      "step = 7200: loss = 0.19618400931358337\n",
      "Average episode length: 0.0\n",
      "step = 7400: loss = 0.19046670198440552\n",
      "Average episode length: 0.0\n",
      "step = 7600: loss = 0.14521214365959167\n",
      "Average episode length: 0.0\n",
      "step = 7800: loss = 0.19923913478851318\n",
      "Average episode length: 0.0\n",
      "step = 8000: loss = 0.15842850506305695\n",
      "Average episode length: 0.0\n",
      "total step is 24137\n",
      "total reward is [12332.355]\n",
      "step = 8000: Average Return = 12332.35546875\n",
      "step = 8200: loss = 0.22230270504951477\n",
      "Average episode length: 0.0\n",
      "step = 8400: loss = 0.1558389961719513\n",
      "Average episode length: 0.0\n",
      "step = 8600: loss = 0.24688689410686493\n",
      "Average episode length: 0.0\n",
      "step = 8800: loss = 0.21324528753757477\n",
      "Average episode length: 0.0\n",
      "step = 9000: loss = 0.1811402589082718\n",
      "Average episode length: 0.0\n",
      "total step is 24137\n",
      "total reward is [12775.777]\n",
      "step = 9000: Average Return = 12775.77734375\n",
      "step = 9200: loss = 0.17898741364479065\n",
      "Average episode length: 0.0\n",
      "step = 9400: loss = 0.17037922143936157\n",
      "Average episode length: 0.0\n",
      "step = 9600: loss = 0.17076171934604645\n",
      "Average episode length: 0.0\n",
      "step = 9800: loss = 0.17362074553966522\n",
      "Average episode length: 0.0\n",
      "step = 10000: loss = 0.24135400354862213\n",
      "Average episode length: 0.0\n",
      "total step is 24137\n",
      "total reward is [13051.056]\n",
      "step = 10000: Average Return = 13051.0556640625\n",
      "step = 10200: loss = 0.1657429337501526\n",
      "Average episode length: 0.0\n",
      "step = 10400: loss = 0.14507213234901428\n",
      "Average episode length: 0.0\n",
      "step = 10600: loss = 0.15837885439395905\n",
      "Average episode length: 0.0\n",
      "step = 10800: loss = 0.11806431412696838\n",
      "Average episode length: 0.0\n",
      "step = 11000: loss = 0.20387744903564453\n",
      "Average episode length: 0.0\n",
      "total step is 24137\n",
      "total reward is [13162.132]\n",
      "step = 11000: Average Return = 13162.1318359375\n",
      "step = 11200: loss = 0.13507583737373352\n",
      "Average episode length: 0.0\n",
      "step = 11400: loss = 0.15499137341976166\n",
      "Average episode length: 0.0\n",
      "step = 11600: loss = 0.12425024062395096\n",
      "Average episode length: 0.0\n",
      "step = 11800: loss = 0.1695862114429474\n",
      "Average episode length: 0.0\n",
      "step = 12000: loss = 0.21140983700752258\n",
      "Average episode length: 0.0\n",
      "total step is 24137\n",
      "total reward is [13206.493]\n",
      "step = 12000: Average Return = 13206.4931640625\n",
      "step = 12200: loss = 0.13003534078598022\n",
      "Average episode length: 0.0\n",
      "step = 12400: loss = 0.2242027074098587\n",
      "Average episode length: 0.0\n",
      "step = 12600: loss = 0.13608624041080475\n",
      "Average episode length: 0.0\n",
      "step = 12800: loss = 0.18896085023880005\n",
      "Average episode length: 0.0\n",
      "step = 13000: loss = 0.1519313007593155\n",
      "Average episode length: 0.0\n",
      "total step is 24137\n",
      "total reward is [13235.864]\n",
      "step = 13000: Average Return = 13235.8642578125\n",
      "step = 13200: loss = 0.152481809258461\n",
      "Average episode length: 0.0\n",
      "step = 13400: loss = 0.2541705369949341\n",
      "Average episode length: 0.0\n",
      "step = 13600: loss = 0.09367941319942474\n",
      "Average episode length: 0.0\n",
      "step = 13800: loss = 0.18524543941020966\n",
      "Average episode length: 0.0\n",
      "step = 14000: loss = 0.22988423705101013\n",
      "Average episode length: 0.0\n",
      "total step is 24137\n",
      "total reward is [13275.077]\n",
      "step = 14000: Average Return = 13275.0771484375\n",
      "step = 14200: loss = 0.15606030821800232\n",
      "Average episode length: 0.0\n",
      "step = 14400: loss = 0.1680242419242859\n",
      "Average episode length: 0.0\n",
      "step = 14600: loss = 0.11989236623048782\n",
      "Average episode length: 0.0\n",
      "step = 14800: loss = 0.11074367165565491\n",
      "Average episode length: 0.0\n",
      "step = 15000: loss = 0.21902748942375183\n",
      "Average episode length: 0.0\n",
      "total step is 24137\n",
      "total reward is [13289.428]\n",
      "step = 15000: Average Return = 13289.427734375\n",
      "step = 15200: loss = 0.08249964565038681\n",
      "Average episode length: 0.0\n",
      "step = 15400: loss = 0.18369314074516296\n",
      "Average episode length: 0.0\n",
      "step = 15600: loss = 0.11669783294200897\n",
      "Average episode length: 0.0\n",
      "step = 15800: loss = 0.09712941199541092\n",
      "Average episode length: 0.0\n",
      "step = 16000: loss = 0.18849696218967438\n",
      "Average episode length: 0.0\n",
      "total step is 24137\n",
      "total reward is [13311.281]\n",
      "step = 16000: Average Return = 13311.28125\n",
      "step = 16200: loss = 0.20769886672496796\n",
      "Average episode length: 0.0\n",
      "step = 16400: loss = 0.11463559418916702\n",
      "Average episode length: 0.0\n",
      "step = 16600: loss = 0.10891193151473999\n",
      "Average episode length: 0.0\n",
      "step = 16800: loss = 0.1567288637161255\n",
      "Average episode length: 0.0\n",
      "step = 17000: loss = 0.1488422155380249\n",
      "Average episode length: 0.0\n",
      "total step is 24137\n",
      "total reward is [13324.522]\n",
      "step = 17000: Average Return = 13324.5224609375\n",
      "step = 17200: loss = 0.12385217100381851\n",
      "Average episode length: 0.0\n",
      "step = 17400: loss = 0.11937084048986435\n",
      "Average episode length: 0.0\n",
      "step = 17600: loss = 0.13350792229175568\n",
      "Average episode length: 0.0\n",
      "step = 17800: loss = 0.13299600780010223\n",
      "Average episode length: 0.0\n",
      "step = 18000: loss = 0.1560211479663849\n",
      "Average episode length: 0.0\n",
      "total step is 24137\n",
      "total reward is [13322.65]\n",
      "step = 18000: Average Return = 13322.650390625\n",
      "step = 18200: loss = 0.10217460989952087\n",
      "Average episode length: 0.0\n",
      "step = 18400: loss = 0.24328355491161346\n",
      "Average episode length: 0.0\n",
      "step = 18600: loss = 0.13220132887363434\n",
      "Average episode length: 0.0\n",
      "step = 18800: loss = 0.1343075931072235\n",
      "Average episode length: 0.0\n",
      "step = 19000: loss = 0.1055004894733429\n",
      "Average episode length: 0.0\n",
      "total step is 24137\n",
      "total reward is [13334.601]\n",
      "step = 19000: Average Return = 13334.6005859375\n",
      "step = 19200: loss = 0.1382445991039276\n",
      "Average episode length: 0.0\n",
      "step = 19400: loss = 0.10068412125110626\n",
      "Average episode length: 0.0\n",
      "step = 19600: loss = 0.13338446617126465\n",
      "Average episode length: 0.0\n",
      "step = 19800: loss = 0.212821364402771\n",
      "Average episode length: 0.0\n",
      "step = 20000: loss = 0.16855552792549133\n",
      "Average episode length: 0.0\n",
      "total step is 24137\n",
      "total reward is [13355.872]\n",
      "step = 20000: Average Return = 13355.8720703125\n"
     ]
    }
   ],
   "source": [
    "# time_step = train_tf_env.reset()\n",
    "final_time_step, policy_state = driver.run()\n",
    "episode_len = []\n",
    "step_len = []\n",
    "losses = []\n",
    "returns = []\n",
    "agent.train_step_counter.assign(0)\n",
    "for i in range(num_iterations+1):\n",
    "    # time_step, _ = driver.run(time_step)\n",
    "    final_time_step, _ = driver.run(final_time_step, policy_state)\n",
    "    \n",
    "    experience, _ = next(data_iter)\n",
    "    train_loss = agent.train(experience=experience)\n",
    "    step = agent.train_step_counter.numpy()\n",
    "\n",
    "    if step % log_interval == 0:\n",
    "        print('step = {0}: loss = {1}'.format(step, train_loss.loss))\n",
    "        episode_len.append(metrics[3].result().numpy())\n",
    "        step_len.append(step)\n",
    "        print('Average episode length: {}'.format(metrics[3].result().numpy()))\n",
    "    \n",
    "    if step % eval_interval == 0:\n",
    "        avg_return = compute_avg_return(eval_tf_env, agent.policy, num_eval_episodes)\n",
    "        print('step = {0}: Average Return = {1}'.format(step, avg_return))\n",
    "        losses.append(train_loss)\n",
    "        returns.append(avg_return)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290c538d-4f9b-44be-9199-0d7ba19c94bd",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cfaf48-1cbe-4997-bf8c-9e06501cf472",
   "metadata": {},
   "source": [
    "### ROCAUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0857199e-8638-460b-826c-19c5d13344f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_q_values, _ = agent._q_network(eval_data_x) \n",
    "train_q_values, _ = agent._q_network(train_data_x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d7cefa44-6c5d-4910-bdf3-7acb871220a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fpr, train_tpr, _ = roc_curve(train_data_y, train_q_values[:, 1])\n",
    "test_fpr, test_tpr, _ = roc_curve(eval_data_y, eval_q_values[:, 1])\n",
    "\n",
    "train_auc = roc_auc_score(y_train, train_q_values[:, 1])\n",
    "test_auc = roc_auc_score(y_test, eval_q_values[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6082ed14-0523-4613-b3a5-258590421afc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(train_fpr, train_tpr, color=\"b\",lw=lw, label=\"Train ROC curve (area = %0.4f)\" % train_auc)\n",
    "plt.plot(test_fpr, test_tpr, color=\"r\",lw=lw, label=\"Test ROC curve (area = %0.4f)\" % test_auc)\n",
    "plt.plot([0, 1], [0, 1], color=\"navy\", lw=lw, linestyle=\"--\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver operating characteristic example\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8dc119d-acf2-4c75-9396-e7ffca70c9c9",
   "metadata": {},
   "source": [
    "## Threshold Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bcdc8b8a-a07d-4697-b67e-af31e2f333b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_analysis(result, label_col, proba_col, tops=None):\n",
    "    if tops is None:\n",
    "        tops = [1]\n",
    "        tops.extend(np.arange(2, 6, 1))\n",
    "        tops.extend(np.arange(10, 105, 5))\n",
    "        tops = [t/100 for t in tops]\n",
    "\n",
    "    threshold_opt = pd.DataFrame()\n",
    "\n",
    "    for top in tops:\n",
    "        percentile = 1-top\n",
    "        threshold = result[proba_col].astype(float).quantile(percentile)\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(result[label_col], result[proba_col] > threshold).ravel()\n",
    "\n",
    "        precision = tp/(tp+fp)\n",
    "        recall = tp/(tp+fn)\n",
    "\n",
    "        f1 = fbeta_score(result[label_col], result[proba_col] > threshold, beta=1)\n",
    "        f2 = fbeta_score(result[label_col], result[proba_col] > threshold, beta=2)\n",
    "\n",
    "        top_idx = top*100\n",
    "        threshold_opt.loc[top_idx, 'threshold'] = threshold\n",
    "        threshold_opt.loc[top_idx, 'lead_size'] = (result[proba_col] > threshold).sum()\n",
    "        threshold_opt.loc[top_idx, 'true_positive'] = tp\n",
    "        threshold_opt.loc[top_idx, 'false_positive'] = fp\n",
    "        threshold_opt.loc[top_idx, 'true_negative'] = tn\n",
    "        threshold_opt.loc[top_idx, 'false_negative'] = fn\n",
    "        threshold_opt.loc[top_idx, 'precision'] = precision\n",
    "        threshold_opt.loc[top_idx, 'recall'] = recall\n",
    "        threshold_opt.loc[top_idx, 'f1'] = f1\n",
    "        threshold_opt.loc[top_idx, 'f2'] = f2\n",
    "\n",
    "        threshold_opt.index.name = 'top'\n",
    "\n",
    "        cols = ['lead_size', 'true_positive', 'false_positive', 'true_negative', 'false_negative']\n",
    "        threshold_opt[cols] = threshold_opt[cols].astype(int)\n",
    "    threshold_opt.reset_index(inplace=True)\n",
    "\n",
    "    return threshold_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b2cf43b8-0055-4ae1-b272-f790602fc972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.1760804 ,  0.2701576 ,  0.51706576, ..., -0.72547156,\n",
       "        0.16329873,  0.12060162], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_q_values[:, 1].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9dee057e-50f8-4819-94a2-cf2ae57e8f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top</th>\n",
       "      <th>threshold</th>\n",
       "      <th>lead_size</th>\n",
       "      <th>true_positive</th>\n",
       "      <th>false_positive</th>\n",
       "      <th>true_negative</th>\n",
       "      <th>false_negative</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.590865</td>\n",
       "      <td>242</td>\n",
       "      <td>242</td>\n",
       "      <td>0</td>\n",
       "      <td>10148</td>\n",
       "      <td>13747</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.017299</td>\n",
       "      <td>0.034010</td>\n",
       "      <td>0.021531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.544975</td>\n",
       "      <td>483</td>\n",
       "      <td>483</td>\n",
       "      <td>0</td>\n",
       "      <td>10148</td>\n",
       "      <td>13506</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.034527</td>\n",
       "      <td>0.066750</td>\n",
       "      <td>0.042790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.488980</td>\n",
       "      <td>725</td>\n",
       "      <td>725</td>\n",
       "      <td>0</td>\n",
       "      <td>10148</td>\n",
       "      <td>13264</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.051826</td>\n",
       "      <td>0.098546</td>\n",
       "      <td>0.063954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.452456</td>\n",
       "      <td>966</td>\n",
       "      <td>966</td>\n",
       "      <td>0</td>\n",
       "      <td>10148</td>\n",
       "      <td>13023</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069054</td>\n",
       "      <td>0.129188</td>\n",
       "      <td>0.084853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.423306</td>\n",
       "      <td>1207</td>\n",
       "      <td>1207</td>\n",
       "      <td>0</td>\n",
       "      <td>10148</td>\n",
       "      <td>12782</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.086282</td>\n",
       "      <td>0.158858</td>\n",
       "      <td>0.105575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.366425</td>\n",
       "      <td>2414</td>\n",
       "      <td>2414</td>\n",
       "      <td>0</td>\n",
       "      <td>10148</td>\n",
       "      <td>11575</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.172564</td>\n",
       "      <td>0.294336</td>\n",
       "      <td>0.206784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.339301</td>\n",
       "      <td>3621</td>\n",
       "      <td>3621</td>\n",
       "      <td>0</td>\n",
       "      <td>10148</td>\n",
       "      <td>10368</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.258846</td>\n",
       "      <td>0.411244</td>\n",
       "      <td>0.303892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.317487</td>\n",
       "      <td>4828</td>\n",
       "      <td>4828</td>\n",
       "      <td>0</td>\n",
       "      <td>10148</td>\n",
       "      <td>9161</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.345128</td>\n",
       "      <td>0.513153</td>\n",
       "      <td>0.397144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.295313</td>\n",
       "      <td>6034</td>\n",
       "      <td>6034</td>\n",
       "      <td>0</td>\n",
       "      <td>10148</td>\n",
       "      <td>7955</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.431339</td>\n",
       "      <td>0.602707</td>\n",
       "      <td>0.486691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.271764</td>\n",
       "      <td>7241</td>\n",
       "      <td>7241</td>\n",
       "      <td>0</td>\n",
       "      <td>10148</td>\n",
       "      <td>6748</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.517621</td>\n",
       "      <td>0.682148</td>\n",
       "      <td>0.572891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0.245088</td>\n",
       "      <td>8448</td>\n",
       "      <td>8448</td>\n",
       "      <td>0</td>\n",
       "      <td>10148</td>\n",
       "      <td>5541</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.603903</td>\n",
       "      <td>0.753042</td>\n",
       "      <td>0.655860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>40.0</td>\n",
       "      <td>0.208487</td>\n",
       "      <td>9655</td>\n",
       "      <td>9648</td>\n",
       "      <td>7</td>\n",
       "      <td>10141</td>\n",
       "      <td>4341</td>\n",
       "      <td>0.999275</td>\n",
       "      <td>0.689685</td>\n",
       "      <td>0.816106</td>\n",
       "      <td>0.735243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>45.0</td>\n",
       "      <td>0.160282</td>\n",
       "      <td>10862</td>\n",
       "      <td>10831</td>\n",
       "      <td>31</td>\n",
       "      <td>10117</td>\n",
       "      <td>3158</td>\n",
       "      <td>0.997146</td>\n",
       "      <td>0.774251</td>\n",
       "      <td>0.871675</td>\n",
       "      <td>0.810485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>50.0</td>\n",
       "      <td>-0.020146</td>\n",
       "      <td>12065</td>\n",
       "      <td>11962</td>\n",
       "      <td>103</td>\n",
       "      <td>10045</td>\n",
       "      <td>2027</td>\n",
       "      <td>0.991463</td>\n",
       "      <td>0.855100</td>\n",
       "      <td>0.918247</td>\n",
       "      <td>0.879287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>55.0</td>\n",
       "      <td>-0.407305</td>\n",
       "      <td>13275</td>\n",
       "      <td>12346</td>\n",
       "      <td>929</td>\n",
       "      <td>9219</td>\n",
       "      <td>1643</td>\n",
       "      <td>0.930019</td>\n",
       "      <td>0.882551</td>\n",
       "      <td>0.905663</td>\n",
       "      <td>0.891653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>60.0</td>\n",
       "      <td>-0.465564</td>\n",
       "      <td>14482</td>\n",
       "      <td>12566</td>\n",
       "      <td>1916</td>\n",
       "      <td>8232</td>\n",
       "      <td>1423</td>\n",
       "      <td>0.867698</td>\n",
       "      <td>0.898277</td>\n",
       "      <td>0.882723</td>\n",
       "      <td>0.891990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>65.0</td>\n",
       "      <td>-0.513559</td>\n",
       "      <td>15689</td>\n",
       "      <td>12818</td>\n",
       "      <td>2871</td>\n",
       "      <td>7277</td>\n",
       "      <td>1171</td>\n",
       "      <td>0.817006</td>\n",
       "      <td>0.916291</td>\n",
       "      <td>0.863805</td>\n",
       "      <td>0.894550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>70.0</td>\n",
       "      <td>-0.551307</td>\n",
       "      <td>16896</td>\n",
       "      <td>12995</td>\n",
       "      <td>3901</td>\n",
       "      <td>6247</td>\n",
       "      <td>994</td>\n",
       "      <td>0.769117</td>\n",
       "      <td>0.928944</td>\n",
       "      <td>0.841509</td>\n",
       "      <td>0.891877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>75.0</td>\n",
       "      <td>-0.585342</td>\n",
       "      <td>18102</td>\n",
       "      <td>13206</td>\n",
       "      <td>4896</td>\n",
       "      <td>5252</td>\n",
       "      <td>783</td>\n",
       "      <td>0.729533</td>\n",
       "      <td>0.944027</td>\n",
       "      <td>0.823034</td>\n",
       "      <td>0.891598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>80.0</td>\n",
       "      <td>-0.616659</td>\n",
       "      <td>19309</td>\n",
       "      <td>13415</td>\n",
       "      <td>5894</td>\n",
       "      <td>4254</td>\n",
       "      <td>574</td>\n",
       "      <td>0.694754</td>\n",
       "      <td>0.958968</td>\n",
       "      <td>0.805754</td>\n",
       "      <td>0.891184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>85.0</td>\n",
       "      <td>-0.650050</td>\n",
       "      <td>20516</td>\n",
       "      <td>13612</td>\n",
       "      <td>6904</td>\n",
       "      <td>3244</td>\n",
       "      <td>377</td>\n",
       "      <td>0.663482</td>\n",
       "      <td>0.973050</td>\n",
       "      <td>0.788987</td>\n",
       "      <td>0.889999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>90.0</td>\n",
       "      <td>-0.695441</td>\n",
       "      <td>21722</td>\n",
       "      <td>13789</td>\n",
       "      <td>7933</td>\n",
       "      <td>2215</td>\n",
       "      <td>200</td>\n",
       "      <td>0.634794</td>\n",
       "      <td>0.985703</td>\n",
       "      <td>0.772255</td>\n",
       "      <td>0.887574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>95.0</td>\n",
       "      <td>-0.789087</td>\n",
       "      <td>22928</td>\n",
       "      <td>13938</td>\n",
       "      <td>8990</td>\n",
       "      <td>1158</td>\n",
       "      <td>51</td>\n",
       "      <td>0.607903</td>\n",
       "      <td>0.996354</td>\n",
       "      <td>0.755099</td>\n",
       "      <td>0.883449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>100.0</td>\n",
       "      <td>-1.552284</td>\n",
       "      <td>24136</td>\n",
       "      <td>13989</td>\n",
       "      <td>10147</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.579591</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.733849</td>\n",
       "      <td>0.873308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      top  threshold  lead_size  true_positive  false_positive  true_negative  \\\n",
       "0     1.0   0.590865        242            242               0          10148   \n",
       "1     2.0   0.544975        483            483               0          10148   \n",
       "2     3.0   0.488980        725            725               0          10148   \n",
       "3     4.0   0.452456        966            966               0          10148   \n",
       "4     5.0   0.423306       1207           1207               0          10148   \n",
       "5    10.0   0.366425       2414           2414               0          10148   \n",
       "6    15.0   0.339301       3621           3621               0          10148   \n",
       "7    20.0   0.317487       4828           4828               0          10148   \n",
       "8    25.0   0.295313       6034           6034               0          10148   \n",
       "9    30.0   0.271764       7241           7241               0          10148   \n",
       "10   35.0   0.245088       8448           8448               0          10148   \n",
       "11   40.0   0.208487       9655           9648               7          10141   \n",
       "12   45.0   0.160282      10862          10831              31          10117   \n",
       "13   50.0  -0.020146      12065          11962             103          10045   \n",
       "14   55.0  -0.407305      13275          12346             929           9219   \n",
       "15   60.0  -0.465564      14482          12566            1916           8232   \n",
       "16   65.0  -0.513559      15689          12818            2871           7277   \n",
       "17   70.0  -0.551307      16896          12995            3901           6247   \n",
       "18   75.0  -0.585342      18102          13206            4896           5252   \n",
       "19   80.0  -0.616659      19309          13415            5894           4254   \n",
       "20   85.0  -0.650050      20516          13612            6904           3244   \n",
       "21   90.0  -0.695441      21722          13789            7933           2215   \n",
       "22   95.0  -0.789087      22928          13938            8990           1158   \n",
       "23  100.0  -1.552284      24136          13989           10147              1   \n",
       "\n",
       "    false_negative  precision    recall        f1        f2  \n",
       "0            13747   1.000000  0.017299  0.034010  0.021531  \n",
       "1            13506   1.000000  0.034527  0.066750  0.042790  \n",
       "2            13264   1.000000  0.051826  0.098546  0.063954  \n",
       "3            13023   1.000000  0.069054  0.129188  0.084853  \n",
       "4            12782   1.000000  0.086282  0.158858  0.105575  \n",
       "5            11575   1.000000  0.172564  0.294336  0.206784  \n",
       "6            10368   1.000000  0.258846  0.411244  0.303892  \n",
       "7             9161   1.000000  0.345128  0.513153  0.397144  \n",
       "8             7955   1.000000  0.431339  0.602707  0.486691  \n",
       "9             6748   1.000000  0.517621  0.682148  0.572891  \n",
       "10            5541   1.000000  0.603903  0.753042  0.655860  \n",
       "11            4341   0.999275  0.689685  0.816106  0.735243  \n",
       "12            3158   0.997146  0.774251  0.871675  0.810485  \n",
       "13            2027   0.991463  0.855100  0.918247  0.879287  \n",
       "14            1643   0.930019  0.882551  0.905663  0.891653  \n",
       "15            1423   0.867698  0.898277  0.882723  0.891990  \n",
       "16            1171   0.817006  0.916291  0.863805  0.894550  \n",
       "17             994   0.769117  0.928944  0.841509  0.891877  \n",
       "18             783   0.729533  0.944027  0.823034  0.891598  \n",
       "19             574   0.694754  0.958968  0.805754  0.891184  \n",
       "20             377   0.663482  0.973050  0.788987  0.889999  \n",
       "21             200   0.634794  0.985703  0.772255  0.887574  \n",
       "22              51   0.607903  0.996354  0.755099  0.883449  \n",
       "23               0   0.579591  1.000000  0.733849  0.873308  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_score = eval_q_values[:, 1].numpy()\n",
    "eval_df = pd.DataFrame({'y_true': y_test, 'y_pred': y_test_score})\n",
    "threshold_analysis(eval_df, 'y_true', 'y_pred', tops=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "95b993b1-1dd0-4a80-b9b5-0576efdaa8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = -0.020146\n",
    "test_df['predict'] = np.where(y_test_score >= threshold, 1, 0)\n",
    "test_df['predicted_reward'] = y_test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7345191c-9d65-4bb8-8aca-c9ba25e34aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Apply</th>\n",
       "      <th>Loan_Amount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predict</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12066</td>\n",
       "      <td>2021</td>\n",
       "      <td>78359000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12071</td>\n",
       "      <td>11968</td>\n",
       "      <td>478607000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID  Apply  Loan_Amount\n",
       "predict                           \n",
       "0        12066   2021   78359000.0\n",
       "1        12071  11968  478607000.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.groupby('predict').agg({\n",
    "    'ID': 'count',\n",
    "    'Apply': 'sum',\n",
    "    'Loan_Amount': 'sum'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "49176f61-4d1a-49d0-8638-a7871c366a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_test_df = test_df.sort_values(by=['predicted_reward'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3d403a01-333b-453a-b81f-0662df432f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_Amount</th>\n",
       "      <th>predicted_reward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68021</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>1.177808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54437</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>1.156346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28152</th>\n",
       "      <td>30000.0</td>\n",
       "      <td>0.661526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28000</th>\n",
       "      <td>107000.0</td>\n",
       "      <td>0.661473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29881</th>\n",
       "      <td>69000.0</td>\n",
       "      <td>0.661216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28442</th>\n",
       "      <td>120000.0</td>\n",
       "      <td>0.661029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28868</th>\n",
       "      <td>49000.0</td>\n",
       "      <td>0.660392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27490</th>\n",
       "      <td>120000.0</td>\n",
       "      <td>0.660137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28405</th>\n",
       "      <td>105000.0</td>\n",
       "      <td>0.660074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29608</th>\n",
       "      <td>64000.0</td>\n",
       "      <td>0.659924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27804</th>\n",
       "      <td>33000.0</td>\n",
       "      <td>0.659719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29660</th>\n",
       "      <td>40000.0</td>\n",
       "      <td>0.659719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5868</th>\n",
       "      <td>43000.0</td>\n",
       "      <td>0.659630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30276</th>\n",
       "      <td>45000.0</td>\n",
       "      <td>0.659324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28112</th>\n",
       "      <td>50000.0</td>\n",
       "      <td>0.659272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27722</th>\n",
       "      <td>51000.0</td>\n",
       "      <td>0.659127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29677</th>\n",
       "      <td>33000.0</td>\n",
       "      <td>0.658851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28312</th>\n",
       "      <td>38000.0</td>\n",
       "      <td>0.658812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6379</th>\n",
       "      <td>37000.0</td>\n",
       "      <td>0.658793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7533</th>\n",
       "      <td>40000.0</td>\n",
       "      <td>0.658718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28599</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>0.655928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5828</th>\n",
       "      <td>32000.0</td>\n",
       "      <td>0.649853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8031</th>\n",
       "      <td>38000.0</td>\n",
       "      <td>0.647074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6802</th>\n",
       "      <td>77000.0</td>\n",
       "      <td>0.646384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7476</th>\n",
       "      <td>36000.0</td>\n",
       "      <td>0.646231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29746</th>\n",
       "      <td>74000.0</td>\n",
       "      <td>0.644041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7698</th>\n",
       "      <td>33000.0</td>\n",
       "      <td>0.642751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28352</th>\n",
       "      <td>29000.0</td>\n",
       "      <td>0.642516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5673</th>\n",
       "      <td>31000.0</td>\n",
       "      <td>0.639024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27385</th>\n",
       "      <td>36000.0</td>\n",
       "      <td>0.637907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Loan_Amount  predicted_reward\n",
       "68021     150000.0          1.177808\n",
       "54437     150000.0          1.156346\n",
       "28152      30000.0          0.661526\n",
       "28000     107000.0          0.661473\n",
       "29881      69000.0          0.661216\n",
       "28442     120000.0          0.661029\n",
       "28868      49000.0          0.660392\n",
       "27490     120000.0          0.660137\n",
       "28405     105000.0          0.660074\n",
       "29608      64000.0          0.659924\n",
       "27804      33000.0          0.659719\n",
       "29660      40000.0          0.659719\n",
       "5868       43000.0          0.659630\n",
       "30276      45000.0          0.659324\n",
       "28112      50000.0          0.659272\n",
       "27722      51000.0          0.659127\n",
       "29677      33000.0          0.658851\n",
       "28312      38000.0          0.658812\n",
       "6379       37000.0          0.658793\n",
       "7533       40000.0          0.658718\n",
       "28599     150000.0          0.655928\n",
       "5828       32000.0          0.649853\n",
       "8031       38000.0          0.647074\n",
       "6802       77000.0          0.646384\n",
       "7476       36000.0          0.646231\n",
       "29746      74000.0          0.644041\n",
       "7698       33000.0          0.642751\n",
       "28352      29000.0          0.642516\n",
       "5673       31000.0          0.639024\n",
       "27385      36000.0          0.637907"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_test_df.loc[:, ['Loan_Amount', 'predicted_reward']].head(30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtualENV",
   "language": "python",
   "name": "virtualenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
