{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb7c9b56-0b9d-48e6-9ad0-912fa10ff547",
   "metadata": {},
   "source": [
    "# DQN Model with Flexible Reward Environment for Banking Lead Conversion Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ba103a1-77f6-4252-97b2-24830f287726",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "curr_folder = globals()['_dh']\n",
    "\n",
    "os.chdir(os.path.join(curr_folder[0], '..'))\n",
    "sys.path.append(os.path.join(curr_folder[0], '..'))\n",
    "sys.path.append(os.path.join(curr_folder[0], '../marketing_rl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d7d6cc2-7949-4225-a6e8-677331659eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report, roc_curve, roc_auc_score, auc, confusion_matrix, fbeta_score\n",
    "\n",
    "import tensorflow as tf\n",
    "import tf_agents.utils.common as common\n",
    "from tf_agents.agents.dqn import dqn_agent\n",
    "from tf_agents.drivers import dynamic_step_driver\n",
    "from tf_agents.networks.q_network import QNetwork\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.replay_buffers import TFUniformReplayBuffer\n",
    "\n",
    "from marketing_rl.environment.flexi_biclass_tf_env import FlexiBiClassTFEnv, EnvMode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04e376e-d1d5-49e2-bcbd-4b3c9a63547e",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "990b942e-6320-485b-8033-36d232a912da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data size is 69713\n"
     ]
    }
   ],
   "source": [
    "data_path = 'data/Banking | Marketing | Leads Conversion Data/train_loan/train.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "print('total data size is', df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45a9ec7-6509-4b4c-a90a-8e41ee2feb87",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f16f2c32-0a97-48ec-9df5-f9e375de1e1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6025275056302268"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['DOB'] = df['DOB'].apply(pd.to_datetime)\n",
    "df['Lead_Creation_Date'] = df['Lead_Creation_Date'].apply(pd.to_datetime)\n",
    "df['Age'] = (df['Lead_Creation_Date'] - df['DOB'])/ np.timedelta64(1, 'Y')\n",
    "df['Age'] = np.where(df['Age'] < 0, np.nan, df['Age'])\n",
    "df['Apply'] = np.where(df['Loan_Amount']>0, 1, 0)\n",
    "df['Apply'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8334307-f8f9-4a1b-aa3a-8a7cc3abf73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_col = 'Apply'\n",
    "index_col = 'ID'\n",
    "date_col = 'Lead_Creation_Date'\n",
    "feat_cols = ['Gender', 'Age', 'City_Category', 'Employer_Category1', 'Employer_Category2', \n",
    "             'Monthly_Income', 'Primary_Bank_Type',\n",
    "             'Source_Category', 'Existing_EMI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b848852-bfc2-48e9-acde-b159fdf9e653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size is 45576\n",
      "test size is 24137\n"
     ]
    }
   ],
   "source": [
    "test_cond = df['Lead_Creation_Date'] > '2016-09-01'\n",
    "train_df = df.loc[~test_cond, :].copy()\n",
    "test_df = df.loc[test_cond, :].copy()\n",
    "print('train size is', train_df.shape[0])\n",
    "print('test size is', test_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d98a2115-9997-44e7-a3d7-279d266c5e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size is 45576\n",
      "test size is 24137\n"
     ]
    }
   ],
   "source": [
    "X_train = train_df[feat_cols]\n",
    "y_train = train_df[label_col]\n",
    "X_test = test_df[feat_cols]\n",
    "y_test = test_df[label_col]\n",
    "print('train size is', X_train.shape[0])\n",
    "print('test size is', X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c639a54d-5b4b-4da7-a032-721bdba6bd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "numer_feats = ['Age', 'Monthly_Income', 'Existing_EMI']\n",
    "numer_transformer = Pipeline(\n",
    "    steps=[(\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", StandardScaler())]\n",
    ")\n",
    "\n",
    "cat_feats = ['Gender', 'City_Category', 'Employer_Category1', 'Employer_Category2', \n",
    "             'Primary_Bank_Type', 'Source_Category']\n",
    "cat_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numer_transformer, numer_feats),\n",
    "        # (\"ordinal\", binary_transformer, binary_feats),\n",
    "        (\"cat\", cat_transformer, cat_feats)\n",
    "    ], sparse_threshold = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4239089-7068-4fb8-b8c3-00f3053a2dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_t = transformer.fit_transform(X_train)\n",
    "X_test_t = transformer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c81d4817-3a74-44bb-b27a-02d9a78462e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sukhumarn/anaconda3/envs/mar_rl/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "transformers = transformer.get_params()['transformers']\n",
    "feature_names = []\n",
    "for name, _, features in transformers:\n",
    "    try:\n",
    "        Var = transformer.named_transformers_[name].get_feature_names().tolist()\n",
    "    except AttributeError:\n",
    "        Var = features\n",
    "    feature_names = feature_names + Var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70be69ee-59d8-44e6-9882-685bcb6cf9cd",
   "metadata": {},
   "source": [
    "## Prep Agents Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04ef89bc-bb59-489f-b4ef-934c4c65f949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] positive sample to negative sample is 1.595296395421673\n"
     ]
    }
   ],
   "source": [
    "pos_neg_ratio = sum(y_train==1)/sum(y_train==0)\n",
    "print('[train] positive sample to negative sample is', pos_neg_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5974277f-fe4c-41c4-8ec7-d2386f92944c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] early stop is 22788.0\n"
     ]
    }
   ],
   "source": [
    "early_stop = train_df.shape[0] * 0.5\n",
    "print(f'[train] early stop is {early_stop}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c74cc566-c069-485f-9306-82fb6309d68b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     28015.000000\n",
       "mean      39237.943959\n",
       "std       30192.645464\n",
       "min        5000.000000\n",
       "25%       20000.000000\n",
       "50%       30000.000000\n",
       "75%       50000.000000\n",
       "max      300000.000000\n",
       "Name: Loan_Amount, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Loan_Amount'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff44e086-2964-4a9e-9a72-b77170f69d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(value, min_val, max_val):\n",
    "    new_value = (value -  min_val)/(max_val - min_val)\n",
    "    return new_value\n",
    "train_df['add_reward'] = train_df['Loan_Amount'].apply(lambda x: normalize_data(x, 5000, 100000))\n",
    "train_df.fillna(0, inplace=True)\n",
    "train_df['add_reward'] = train_df['add_reward'].clip(0, 1)\n",
    "\n",
    "test_df['add_reward'] = test_df['Loan_Amount'].apply(lambda x: normalize_data(x, 5000, 100000))\n",
    "test_df.fillna(0, inplace=True)\n",
    "test_df['add_reward'] = test_df['add_reward'].clip(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e08c5e68-b2b2-4b07-af2c-f79483b8e7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_x = np.array(X_train_t)\n",
    "train_data_y = np.array(y_train)\n",
    "reward = np.array(train_df['add_reward'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff72a0cc-08b2-44cb-b515-dfd56cd28a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_env = FlexiBiClassTFEnv(data_x=train_data_x, data_y=train_data_y, pos_neg_ratio=1, \n",
    "                              discount=0.1, reward=reward, early_stop=None)\n",
    "train_tf_env = tf_py_environment.TFPyEnvironment(train_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58c6f240-c516-47fb-9c00-a949e3d1a706",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data_x = np.array(X_test_t)\n",
    "eval_data_y = np.array(y_test)\n",
    "eval_reward = np.array(test_df['add_reward'])\n",
    "\n",
    "eval_env = FlexiBiClassTFEnv(data_x=eval_data_x, data_y=eval_data_y, reward=eval_reward, \n",
    "                        pos_neg_ratio=1, mode=EnvMode.TEST)\n",
    "eval_tf_env = tf_py_environment.TFPyEnvironment(eval_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4d320d-28d8-4a06-8c71-f8092e85d9e6",
   "metadata": {},
   "source": [
    "## Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991156f5-6c80-4b58-98fc-5cb5091d2800",
   "metadata": {},
   "source": [
    "### Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5eff2fe-23d6-4533-8c61-b62892d7897e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameters\n",
    "fc_layers = (64,)\n",
    "learning_rate = 1e-5\n",
    "batch_size = 64\n",
    "replay_buffer_capacity = 100000\n",
    "\n",
    "num_iterations = 20000\n",
    "num_eval_episodes = 1\n",
    "\n",
    "log_interval = 200\n",
    "eval_interval = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401cbe00-0b95-4857-8ea8-69e4d829edcb",
   "metadata": {},
   "source": [
    "### Set Q-network and initialize agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8cd8b570-d2e7-49bf-b0df-b670f27c00cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# q network\n",
    "q_net = QNetwork(\n",
    "    input_tensor_spec = train_tf_env.observation_spec(),\n",
    "    action_spec = train_tf_env.action_spec(),\n",
    "    fc_layer_params = fc_layers,\n",
    ")\n",
    "\n",
    "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "# train_step_counter = tf.compat.v2.Variable(0)\n",
    "global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "# dqn agent\n",
    "agent = dqn_agent.DqnAgent(\n",
    "    time_step_spec = train_tf_env.time_step_spec(),\n",
    "    action_spec = train_tf_env.action_spec(),\n",
    "    q_network = q_net,\n",
    "    optimizer = optimizer,\n",
    "    td_errors_loss_fn = common.element_wise_squared_loss,\n",
    "    train_step_counter = global_step,\n",
    "    emit_log_probability = True\n",
    ")\n",
    "agent.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f8decdd0-20a9-424a-adc8-d2e2186e95df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size: None\n"
     ]
    }
   ],
   "source": [
    "# initiate replay buffer for training\n",
    "replay_buffer = TFUniformReplayBuffer(\n",
    "    data_spec = agent.collect_data_spec,\n",
    "    batch_size = train_tf_env.batch_size,\n",
    "    max_length = replay_buffer_capacity,\n",
    ")\n",
    "print(\"Batch Size: {}\".format(train_env.batch_size))\n",
    "\n",
    "replay_observer = [replay_buffer.add_batch]\n",
    "metrics = [\n",
    "    tf_metrics.NumberOfEpisodes(),\n",
    "    tf_metrics.EnvironmentSteps(),\n",
    "    tf_metrics.AverageReturnMetric(),\n",
    "    tf_metrics.AverageEpisodeLengthMetric(),\n",
    "    \n",
    "]\n",
    "\n",
    "# policy\n",
    "eval_policy = agent.policy\n",
    "collect_policy = agent.collect_policy\n",
    "\n",
    "agent.train = common.function(agent.train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b985028-cb8d-4257-95ca-0bee3743a778",
   "metadata": {},
   "source": [
    "### Set Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "22d09c99-784f-4e10-ae88-69f309e5d6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_folder = 'banking_lead_cp'\n",
    "train_checkpointer = common.Checkpointer(\n",
    "    ckpt_dir=checkpoint_folder,\n",
    "    max_to_keep=1,\n",
    "    agent=agent,\n",
    "    policy=agent.policy,\n",
    "    replay_buffer=replay_buffer,\n",
    "    global_step=global_step\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96f3438-54ab-417d-b80f-5aead5241f87",
   "metadata": {},
   "source": [
    "### Train agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "313bb481-e000-41ab-9f32-1b40703b6ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/sukhumarn/anaconda3/envs/mar_rl/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:377: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `as_dataset(..., single_deterministic_pass=False) instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/sukhumarn/anaconda3/envs/mar_rl/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:377: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `as_dataset(..., single_deterministic_pass=False) instead.\n"
     ]
    }
   ],
   "source": [
    "dataset = replay_buffer.as_dataset(\n",
    "    num_parallel_calls = 3, \n",
    "    sample_batch_size = batch_size,\n",
    "    num_steps = 2\n",
    ").prefetch(3)\n",
    "\n",
    "driver = dynamic_step_driver.DynamicStepDriver(\n",
    "    env = train_tf_env,\n",
    "    policy = collect_policy,\n",
    "    observers = replay_observer + metrics,\n",
    ")\n",
    "\n",
    "data_iter = iter(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aa06940e-9b5b-4fea-b20b-a2182747afc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_avg_return(environment, policy, num_episodes=1):\n",
    "    total_return = 0.0\n",
    "    total_step = 0\n",
    "    for i in range(num_episodes):\n",
    "        time_step = environment.reset()\n",
    "        episode_return = 0.0\n",
    "\n",
    "        while not time_step.is_last():\n",
    "            action_step = policy.action(time_step)\n",
    "            time_step = environment.step(action_step.action)\n",
    "            episode_return += time_step.reward\n",
    "            total_step += 1\n",
    "        total_return += episode_return\n",
    "            \n",
    "    print(f'total step is {total_step}')\n",
    "    print(f'total reward is {total_return}')\n",
    "    avg_return = total_return / num_episodes\n",
    "    return avg_return.numpy()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6801ef0-152d-4ab6-bed6-6c9cecb1e699",
   "metadata": {},
   "source": [
    "### Continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7a34ef4b-1bf4-43d3-a4d5-efdf4a11e697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step is <tf.Variable 'global_step:0' shape=() dtype=int64, numpy=38000>\n",
      "num_iterations is 3000\n"
     ]
    }
   ],
   "source": [
    "num_iterations = 3000\n",
    "train_checkpointer.initialize_or_restore()\n",
    "global_step = tf.compat.v1.train.get_global_step()\n",
    "print('global step is', global_step)\n",
    "print('num_iterations is', num_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f84db8-ed22-4411-8307-27ae0a219df0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 38200: loss = 0.131815105676651\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  38202\n",
      "step = 38400: loss = 0.1529705673456192\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  38402\n",
      "step = 38600: loss = 0.14880873262882233\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  38602\n",
      "step = 38800: loss = 0.07481971383094788\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  38802\n",
      "step = 39000: loss = 0.17149858176708221\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  39002\n",
      "total step is 24137\n",
      "total reward is [13417.083]\n",
      "step = 39000: Average Return = 13417.0830078125\n",
      "step = 39200: loss = 0.14990602433681488\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  39202\n",
      "step = 39400: loss = 0.12195958197116852\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  39402\n",
      "step = 39600: loss = 0.14840289950370789\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  39602\n",
      "step = 39800: loss = 0.100040003657341\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  39802\n",
      "step = 40000: loss = 0.12579715251922607\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  40002\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_iterations+1):\n",
    "    # time_step, _ = driver.run(time_step)\n",
    "    final_time_step, _ = driver.run(final_time_step, policy_state)\n",
    "    \n",
    "    experience, _ = next(data_iter)\n",
    "    train_loss = agent.train(experience=experience)\n",
    "    step = agent.train_step_counter.numpy()\n",
    "\n",
    "    if step % log_interval == 0:\n",
    "        print('step = {0}: loss = {1}'.format(step, train_loss.loss))\n",
    "        episode_len.append(metrics[3].result().numpy())\n",
    "        step_len.append(step)\n",
    "        print('Average episode length: {}'.format(metrics[3].result().numpy()))\n",
    "        print('Number of Steps: ', metrics[1].result().numpy())\n",
    "    \n",
    "    if step % eval_interval == 0:\n",
    "        avg_return = compute_avg_return(eval_tf_env, agent.policy, num_eval_episodes)\n",
    "        print('step = {0}: Average Return = {1}'.format(step, avg_return))\n",
    "        losses.append(train_loss)\n",
    "        returns.append(avg_return)\n",
    "        train_checkpointer.save(global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7216fc10-b81b-4b56-8157-a6026e185a1e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 1200: loss = 0.5865898728370667\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  1202\n",
      "step = 1400: loss = 0.4765845537185669\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  1402\n",
      "step = 1600: loss = 0.48599857091903687\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  1602\n",
      "step = 1800: loss = 0.4826161861419678\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  1802\n",
      "step = 2000: loss = 0.4848335087299347\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  2002\n",
      "total step is 24137\n",
      "total reward is [5364.0435]\n",
      "step = 2000: Average Return = 5364.04345703125\n",
      "step = 2200: loss = 0.3921959400177002\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  2202\n",
      "step = 2400: loss = 0.48763012886047363\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  2402\n",
      "step = 2600: loss = 0.395107626914978\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  2602\n",
      "step = 2800: loss = 0.4271319508552551\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  2802\n",
      "step = 3000: loss = 0.32149916887283325\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  3002\n",
      "total step is 24137\n",
      "total reward is [5670.6006]\n",
      "step = 3000: Average Return = 5670.6005859375\n",
      "step = 3200: loss = 0.37124815583229065\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  3202\n",
      "step = 3400: loss = 0.33108630776405334\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  3402\n",
      "step = 3600: loss = 0.43829771876335144\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  3602\n",
      "step = 3800: loss = 0.32659152150154114\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  3802\n",
      "step = 4000: loss = 0.3532947599887848\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  4002\n",
      "total step is 24137\n",
      "total reward is [6462.682]\n",
      "step = 4000: Average Return = 6462.68212890625\n",
      "step = 4200: loss = 0.4035237431526184\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  4202\n",
      "step = 4400: loss = 0.29742830991744995\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  4402\n",
      "step = 4600: loss = 0.3389670252799988\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  4602\n",
      "step = 4800: loss = 0.27799737453460693\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  4802\n",
      "step = 5000: loss = 0.28288960456848145\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  5002\n",
      "total step is 24137\n",
      "total reward is [7459.516]\n",
      "step = 5000: Average Return = 7459.51611328125\n",
      "step = 5200: loss = 0.269107460975647\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  5202\n",
      "step = 5400: loss = 0.2553786635398865\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  5402\n",
      "step = 5600: loss = 0.2694692611694336\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  5602\n",
      "step = 5800: loss = 0.2327338308095932\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  5802\n",
      "step = 6000: loss = 0.27256882190704346\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  6002\n",
      "total step is 24137\n",
      "total reward is [8770.895]\n",
      "step = 6000: Average Return = 8770.89453125\n",
      "step = 6200: loss = 0.24616903066635132\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  6202\n",
      "step = 6400: loss = 0.21801266074180603\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  6402\n",
      "step = 6600: loss = 0.18498024344444275\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  6602\n",
      "step = 6800: loss = 0.26511526107788086\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  6802\n",
      "step = 7000: loss = 0.2361997365951538\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  7002\n",
      "total step is 24137\n",
      "total reward is [10230.033]\n",
      "step = 7000: Average Return = 10230.033203125\n",
      "step = 7200: loss = 0.24766463041305542\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  7202\n",
      "step = 7400: loss = 0.20076340436935425\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  7402\n",
      "step = 7600: loss = 0.18147706985473633\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  7602\n",
      "step = 7800: loss = 0.204025536775589\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  7802\n",
      "step = 8000: loss = 0.1828061044216156\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  8002\n",
      "total step is 24137\n",
      "total reward is [11290.16]\n",
      "step = 8000: Average Return = 11290.16015625\n",
      "step = 8200: loss = 0.2094392478466034\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  8202\n",
      "step = 8400: loss = 0.23403069376945496\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  8402\n",
      "step = 8600: loss = 0.17559395730495453\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  8602\n",
      "step = 8800: loss = 0.18408089876174927\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  8802\n",
      "step = 9000: loss = 0.24269108474254608\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  9002\n",
      "total step is 24137\n",
      "total reward is [12150.773]\n",
      "step = 9000: Average Return = 12150.7734375\n",
      "step = 9200: loss = 0.2030007541179657\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  9202\n",
      "step = 9400: loss = 0.19331929087638855\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  9402\n",
      "step = 9600: loss = 0.16484257578849792\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  9602\n",
      "step = 9800: loss = 0.17938785254955292\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  9802\n",
      "step = 10000: loss = 0.13341453671455383\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  10002\n",
      "total step is 24137\n",
      "total reward is [12646.432]\n",
      "step = 10000: Average Return = 12646.431640625\n",
      "step = 10200: loss = 0.1964935064315796\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  10202\n",
      "step = 10400: loss = 0.18963968753814697\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  10402\n",
      "step = 10600: loss = 0.17409753799438477\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  10602\n",
      "step = 10800: loss = 0.17475619912147522\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  10802\n",
      "step = 11000: loss = 0.22444850206375122\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  11002\n",
      "total step is 24137\n",
      "total reward is [12891.747]\n",
      "step = 11000: Average Return = 12891.7470703125\n",
      "step = 11200: loss = 0.1638202667236328\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  11202\n",
      "step = 11400: loss = 0.24510419368743896\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  11402\n",
      "step = 11600: loss = 0.18622829020023346\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  11602\n",
      "step = 11800: loss = 0.16059133410453796\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  11802\n",
      "step = 12000: loss = 0.12575311958789825\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  12002\n",
      "total step is 24137\n",
      "total reward is [13029.109]\n",
      "step = 12000: Average Return = 13029.109375\n",
      "step = 12200: loss = 0.13992847502231598\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  12202\n",
      "step = 12400: loss = 0.08278515189886093\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  12402\n",
      "step = 12600: loss = 0.21910211443901062\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  12602\n",
      "step = 12800: loss = 0.23711997270584106\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  12802\n",
      "step = 13000: loss = 0.16282391548156738\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  13002\n",
      "total step is 24137\n",
      "total reward is [13175.854]\n",
      "step = 13000: Average Return = 13175.853515625\n",
      "step = 13200: loss = 0.1729452908039093\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  13202\n",
      "step = 13400: loss = 0.13455045223236084\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  13402\n",
      "step = 13600: loss = 0.1257467120885849\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  13602\n",
      "step = 13800: loss = 0.12249661237001419\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  13802\n",
      "step = 14000: loss = 0.12488343566656113\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  14002\n",
      "total step is 24137\n",
      "total reward is [13275.191]\n",
      "step = 14000: Average Return = 13275.19140625\n",
      "step = 14200: loss = 0.09720343351364136\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  14202\n",
      "step = 14400: loss = 0.1770385354757309\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  14402\n",
      "step = 14600: loss = 0.14901518821716309\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  14602\n",
      "step = 14800: loss = 0.13049528002738953\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  14802\n",
      "step = 15000: loss = 0.1683405339717865\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  15002\n",
      "total step is 24137\n",
      "total reward is [13345.804]\n",
      "step = 15000: Average Return = 13345.8037109375\n",
      "step = 15200: loss = 0.23261934518814087\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  15202\n",
      "step = 15400: loss = 0.13600139319896698\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  15402\n",
      "step = 15600: loss = 0.13807106018066406\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  15602\n",
      "step = 15800: loss = 0.13783922791481018\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  15802\n",
      "step = 16000: loss = 0.12099818885326385\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  16002\n",
      "total step is 24137\n",
      "total reward is [13362.921]\n",
      "step = 16000: Average Return = 13362.9208984375\n",
      "step = 16200: loss = 0.1403658390045166\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  16202\n",
      "step = 16400: loss = 0.15109847486019135\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  16402\n",
      "step = 16600: loss = 0.1741006225347519\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  16602\n",
      "step = 16800: loss = 0.08411458134651184\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  16802\n",
      "step = 17000: loss = 0.19880470633506775\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  17002\n",
      "total step is 24137\n",
      "total reward is [13385.286]\n",
      "step = 17000: Average Return = 13385.2861328125\n",
      "step = 17200: loss = 0.15578976273536682\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  17202\n",
      "step = 17400: loss = 0.13679088652133942\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  17402\n",
      "step = 17600: loss = 0.14309540390968323\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  17602\n",
      "step = 17800: loss = 0.21432241797447205\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  17802\n",
      "step = 18000: loss = 0.1086324155330658\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  18002\n",
      "total step is 24137\n",
      "total reward is [13395.008]\n",
      "step = 18000: Average Return = 13395.0078125\n",
      "step = 18200: loss = 0.16517920792102814\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  18202\n",
      "step = 18400: loss = 0.12482254952192307\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  18402\n",
      "step = 18600: loss = 0.21208547055721283\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  18602\n",
      "step = 18800: loss = 0.08314228057861328\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  18802\n",
      "step = 19000: loss = 0.15120042860507965\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  19002\n",
      "total step is 24137\n",
      "total reward is [13394.334]\n",
      "step = 19000: Average Return = 13394.333984375\n",
      "step = 19200: loss = 0.09193477034568787\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  19202\n",
      "step = 19400: loss = 0.08734747022390366\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  19402\n",
      "step = 19600: loss = 0.25274354219436646\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  19602\n",
      "step = 19800: loss = 0.13453523814678192\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  19802\n",
      "step = 20000: loss = 0.1113823652267456\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  20002\n",
      "total step is 24137\n",
      "total reward is [13389.214]\n",
      "step = 20000: Average Return = 13389.2138671875\n",
      "step = 20200: loss = 0.0960889607667923\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  20202\n",
      "step = 20400: loss = 0.07843782007694244\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  20402\n",
      "step = 20600: loss = 0.11635690927505493\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  20602\n",
      "step = 20800: loss = 0.1581898331642151\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  20802\n",
      "step = 21000: loss = 0.13115723431110382\n",
      "Average episode length: 0.0\n",
      "Number of Steps:  21002\n",
      "total step is 24137\n",
      "total reward is [13390.571]\n",
      "step = 21000: Average Return = 13390.5712890625\n"
     ]
    }
   ],
   "source": [
    "# time_step = train_tf_env.reset()\n",
    "final_time_step, policy_state = driver.run()\n",
    "episode_len = []\n",
    "step_len = []\n",
    "losses = []\n",
    "returns = []\n",
    "# agent.train_step_counter.assign(0)\n",
    "for i in range(num_iterations+1):\n",
    "    # time_step, _ = driver.run(time_step)\n",
    "    final_time_step, _ = driver.run(final_time_step, policy_state)\n",
    "    \n",
    "    experience, _ = next(data_iter)\n",
    "    train_loss = agent.train(experience=experience)\n",
    "    step = agent.train_step_counter.numpy()\n",
    "\n",
    "    if step % log_interval == 0:\n",
    "        print('step = {0}: loss = {1}'.format(step, train_loss.loss))\n",
    "        episode_len.append(metrics[3].result().numpy())\n",
    "        step_len.append(step)\n",
    "        print('Average episode length: {}'.format(metrics[3].result().numpy()))\n",
    "        print('Number of Steps: ', metrics[1].result().numpy())\n",
    "    \n",
    "    if step % eval_interval == 0:\n",
    "        avg_return = compute_avg_return(eval_tf_env, agent.policy, num_eval_episodes)\n",
    "        print('step = {0}: Average Return = {1}'.format(step, avg_return))\n",
    "        losses.append(train_loss)\n",
    "        returns.append(avg_return)\n",
    "        train_checkpointer.save(global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290c538d-4f9b-44be-9199-0d7ba19c94bd",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cfaf48-1cbe-4997-bf8c-9e06501cf472",
   "metadata": {},
   "source": [
    "### ROCAUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0857199e-8638-460b-826c-19c5d13344f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'agent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m eval_q_values, _ \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241m.\u001b[39m_q_network(eval_data_x) \n\u001b[1;32m      2\u001b[0m train_q_values, _ \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39m_q_network(train_data_x)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'agent' is not defined"
     ]
    }
   ],
   "source": [
    "eval_q_values, _ = agent._q_network(eval_data_x) \n",
    "train_q_values, _ = agent._q_network(train_data_x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d7cefa44-6c5d-4910-bdf3-7acb871220a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fpr, train_tpr, _ = roc_curve(train_data_y, train_q_values[:, 1])\n",
    "test_fpr, test_tpr, _ = roc_curve(eval_data_y, eval_q_values[:, 1])\n",
    "\n",
    "train_auc = roc_auc_score(y_train, train_q_values[:, 1])\n",
    "test_auc = roc_auc_score(y_test, eval_q_values[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6082ed14-0523-4613-b3a5-258590421afc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(train_fpr, train_tpr, color=\"b\",lw=lw, label=\"Train ROC curve (area = %0.4f)\" % train_auc)\n",
    "plt.plot(test_fpr, test_tpr, color=\"r\",lw=lw, label=\"Test ROC curve (area = %0.4f)\" % test_auc)\n",
    "plt.plot([0, 1], [0, 1], color=\"navy\", lw=lw, linestyle=\"--\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver operating characteristic example\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8dc119d-acf2-4c75-9396-e7ffca70c9c9",
   "metadata": {},
   "source": [
    "## Threshold Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bcdc8b8a-a07d-4697-b67e-af31e2f333b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_analysis(result, label_col, proba_col, tops=None):\n",
    "    if tops is None:\n",
    "        tops = [1]\n",
    "        tops.extend(np.arange(2, 6, 1))\n",
    "        tops.extend(np.arange(10, 105, 5))\n",
    "        tops = [t/100 for t in tops]\n",
    "\n",
    "    threshold_opt = pd.DataFrame()\n",
    "\n",
    "    for top in tops:\n",
    "        percentile = 1-top\n",
    "        threshold = result[proba_col].astype(float).quantile(percentile)\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(result[label_col], result[proba_col] > threshold).ravel()\n",
    "\n",
    "        precision = tp/(tp+fp)\n",
    "        recall = tp/(tp+fn)\n",
    "\n",
    "        f1 = fbeta_score(result[label_col], result[proba_col] > threshold, beta=1)\n",
    "        f2 = fbeta_score(result[label_col], result[proba_col] > threshold, beta=2)\n",
    "\n",
    "        top_idx = top*100\n",
    "        threshold_opt.loc[top_idx, 'threshold'] = threshold\n",
    "        threshold_opt.loc[top_idx, 'lead_size'] = (result[proba_col] > threshold).sum()\n",
    "        threshold_opt.loc[top_idx, 'true_positive'] = tp\n",
    "        threshold_opt.loc[top_idx, 'false_positive'] = fp\n",
    "        threshold_opt.loc[top_idx, 'true_negative'] = tn\n",
    "        threshold_opt.loc[top_idx, 'false_negative'] = fn\n",
    "        threshold_opt.loc[top_idx, 'precision'] = precision\n",
    "        threshold_opt.loc[top_idx, 'recall'] = recall\n",
    "        threshold_opt.loc[top_idx, 'f1'] = f1\n",
    "        threshold_opt.loc[top_idx, 'f2'] = f2\n",
    "\n",
    "        threshold_opt.index.name = 'top'\n",
    "\n",
    "        cols = ['lead_size', 'true_positive', 'false_positive', 'true_negative', 'false_negative']\n",
    "        threshold_opt[cols] = threshold_opt[cols].astype(int)\n",
    "    threshold_opt.reset_index(inplace=True)\n",
    "\n",
    "    return threshold_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b2cf43b8-0055-4ae1-b272-f790602fc972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.34335107,  0.2852049 ,  0.48469412, ..., -0.80023766,\n",
       "        0.31356728,  0.16732672], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_q_values[:, 1].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9dee057e-50f8-4819-94a2-cf2ae57e8f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top</th>\n",
       "      <th>threshold</th>\n",
       "      <th>lead_size</th>\n",
       "      <th>true_positive</th>\n",
       "      <th>false_positive</th>\n",
       "      <th>true_negative</th>\n",
       "      <th>false_negative</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.577690</td>\n",
       "      <td>242</td>\n",
       "      <td>242</td>\n",
       "      <td>0</td>\n",
       "      <td>10148</td>\n",
       "      <td>13747</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.017299</td>\n",
       "      <td>0.034010</td>\n",
       "      <td>0.021531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.534465</td>\n",
       "      <td>483</td>\n",
       "      <td>483</td>\n",
       "      <td>0</td>\n",
       "      <td>10148</td>\n",
       "      <td>13506</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.034527</td>\n",
       "      <td>0.066750</td>\n",
       "      <td>0.042790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.489860</td>\n",
       "      <td>725</td>\n",
       "      <td>725</td>\n",
       "      <td>0</td>\n",
       "      <td>10148</td>\n",
       "      <td>13264</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.051826</td>\n",
       "      <td>0.098546</td>\n",
       "      <td>0.063954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.465965</td>\n",
       "      <td>966</td>\n",
       "      <td>966</td>\n",
       "      <td>0</td>\n",
       "      <td>10148</td>\n",
       "      <td>13023</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069054</td>\n",
       "      <td>0.129188</td>\n",
       "      <td>0.084853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.451753</td>\n",
       "      <td>1207</td>\n",
       "      <td>1207</td>\n",
       "      <td>0</td>\n",
       "      <td>10148</td>\n",
       "      <td>12782</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.086282</td>\n",
       "      <td>0.158858</td>\n",
       "      <td>0.105575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.416994</td>\n",
       "      <td>2414</td>\n",
       "      <td>2414</td>\n",
       "      <td>0</td>\n",
       "      <td>10148</td>\n",
       "      <td>11575</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.172564</td>\n",
       "      <td>0.294336</td>\n",
       "      <td>0.206784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.396867</td>\n",
       "      <td>3621</td>\n",
       "      <td>3621</td>\n",
       "      <td>0</td>\n",
       "      <td>10148</td>\n",
       "      <td>10368</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.258846</td>\n",
       "      <td>0.411244</td>\n",
       "      <td>0.303892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.376674</td>\n",
       "      <td>4828</td>\n",
       "      <td>4828</td>\n",
       "      <td>0</td>\n",
       "      <td>10148</td>\n",
       "      <td>9161</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.345128</td>\n",
       "      <td>0.513153</td>\n",
       "      <td>0.397144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.358188</td>\n",
       "      <td>6034</td>\n",
       "      <td>6034</td>\n",
       "      <td>0</td>\n",
       "      <td>10148</td>\n",
       "      <td>7955</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.431339</td>\n",
       "      <td>0.602707</td>\n",
       "      <td>0.486691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.336485</td>\n",
       "      <td>7241</td>\n",
       "      <td>7241</td>\n",
       "      <td>0</td>\n",
       "      <td>10148</td>\n",
       "      <td>6748</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.517621</td>\n",
       "      <td>0.682148</td>\n",
       "      <td>0.572891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0.312077</td>\n",
       "      <td>8448</td>\n",
       "      <td>8447</td>\n",
       "      <td>1</td>\n",
       "      <td>10147</td>\n",
       "      <td>5542</td>\n",
       "      <td>0.999882</td>\n",
       "      <td>0.603832</td>\n",
       "      <td>0.752953</td>\n",
       "      <td>0.655782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>40.0</td>\n",
       "      <td>0.280418</td>\n",
       "      <td>9654</td>\n",
       "      <td>9649</td>\n",
       "      <td>5</td>\n",
       "      <td>10143</td>\n",
       "      <td>4340</td>\n",
       "      <td>0.999482</td>\n",
       "      <td>0.689756</td>\n",
       "      <td>0.816225</td>\n",
       "      <td>0.735330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>45.0</td>\n",
       "      <td>0.227410</td>\n",
       "      <td>10862</td>\n",
       "      <td>10845</td>\n",
       "      <td>17</td>\n",
       "      <td>10131</td>\n",
       "      <td>3144</td>\n",
       "      <td>0.998435</td>\n",
       "      <td>0.775252</td>\n",
       "      <td>0.872802</td>\n",
       "      <td>0.811533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.002343</td>\n",
       "      <td>12068</td>\n",
       "      <td>11976</td>\n",
       "      <td>92</td>\n",
       "      <td>10056</td>\n",
       "      <td>2013</td>\n",
       "      <td>0.992377</td>\n",
       "      <td>0.856101</td>\n",
       "      <td>0.919216</td>\n",
       "      <td>0.880278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>55.0</td>\n",
       "      <td>-0.495966</td>\n",
       "      <td>13275</td>\n",
       "      <td>12413</td>\n",
       "      <td>862</td>\n",
       "      <td>9286</td>\n",
       "      <td>1576</td>\n",
       "      <td>0.935066</td>\n",
       "      <td>0.887340</td>\n",
       "      <td>0.910578</td>\n",
       "      <td>0.896491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>60.0</td>\n",
       "      <td>-0.564497</td>\n",
       "      <td>14482</td>\n",
       "      <td>12686</td>\n",
       "      <td>1796</td>\n",
       "      <td>8352</td>\n",
       "      <td>1303</td>\n",
       "      <td>0.875984</td>\n",
       "      <td>0.906855</td>\n",
       "      <td>0.891152</td>\n",
       "      <td>0.900508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>65.0</td>\n",
       "      <td>-0.600024</td>\n",
       "      <td>15689</td>\n",
       "      <td>12871</td>\n",
       "      <td>2818</td>\n",
       "      <td>7330</td>\n",
       "      <td>1118</td>\n",
       "      <td>0.820384</td>\n",
       "      <td>0.920080</td>\n",
       "      <td>0.867377</td>\n",
       "      <td>0.898248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>70.0</td>\n",
       "      <td>-0.633855</td>\n",
       "      <td>16896</td>\n",
       "      <td>13064</td>\n",
       "      <td>3832</td>\n",
       "      <td>6316</td>\n",
       "      <td>925</td>\n",
       "      <td>0.773201</td>\n",
       "      <td>0.933877</td>\n",
       "      <td>0.845977</td>\n",
       "      <td>0.896612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>75.0</td>\n",
       "      <td>-0.670906</td>\n",
       "      <td>18102</td>\n",
       "      <td>13279</td>\n",
       "      <td>4823</td>\n",
       "      <td>5325</td>\n",
       "      <td>710</td>\n",
       "      <td>0.733565</td>\n",
       "      <td>0.949246</td>\n",
       "      <td>0.827584</td>\n",
       "      <td>0.896527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>80.0</td>\n",
       "      <td>-0.704614</td>\n",
       "      <td>19309</td>\n",
       "      <td>13519</td>\n",
       "      <td>5790</td>\n",
       "      <td>4358</td>\n",
       "      <td>470</td>\n",
       "      <td>0.700140</td>\n",
       "      <td>0.966402</td>\n",
       "      <td>0.812001</td>\n",
       "      <td>0.898093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>85.0</td>\n",
       "      <td>-0.740393</td>\n",
       "      <td>20516</td>\n",
       "      <td>13702</td>\n",
       "      <td>6814</td>\n",
       "      <td>3334</td>\n",
       "      <td>287</td>\n",
       "      <td>0.667869</td>\n",
       "      <td>0.979484</td>\n",
       "      <td>0.794204</td>\n",
       "      <td>0.895883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>90.0</td>\n",
       "      <td>-0.781814</td>\n",
       "      <td>21723</td>\n",
       "      <td>13841</td>\n",
       "      <td>7882</td>\n",
       "      <td>2266</td>\n",
       "      <td>148</td>\n",
       "      <td>0.637159</td>\n",
       "      <td>0.989420</td>\n",
       "      <td>0.775146</td>\n",
       "      <td>0.890910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>95.0</td>\n",
       "      <td>-0.841766</td>\n",
       "      <td>22930</td>\n",
       "      <td>13958</td>\n",
       "      <td>8972</td>\n",
       "      <td>1176</td>\n",
       "      <td>31</td>\n",
       "      <td>0.608722</td>\n",
       "      <td>0.997784</td>\n",
       "      <td>0.756142</td>\n",
       "      <td>0.884694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>100.0</td>\n",
       "      <td>-1.479267</td>\n",
       "      <td>24136</td>\n",
       "      <td>13989</td>\n",
       "      <td>10147</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.579591</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.733849</td>\n",
       "      <td>0.873308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      top  threshold  lead_size  true_positive  false_positive  true_negative  \\\n",
       "0     1.0   0.577690        242            242               0          10148   \n",
       "1     2.0   0.534465        483            483               0          10148   \n",
       "2     3.0   0.489860        725            725               0          10148   \n",
       "3     4.0   0.465965        966            966               0          10148   \n",
       "4     5.0   0.451753       1207           1207               0          10148   \n",
       "5    10.0   0.416994       2414           2414               0          10148   \n",
       "6    15.0   0.396867       3621           3621               0          10148   \n",
       "7    20.0   0.376674       4828           4828               0          10148   \n",
       "8    25.0   0.358188       6034           6034               0          10148   \n",
       "9    30.0   0.336485       7241           7241               0          10148   \n",
       "10   35.0   0.312077       8448           8447               1          10147   \n",
       "11   40.0   0.280418       9654           9649               5          10143   \n",
       "12   45.0   0.227410      10862          10845              17          10131   \n",
       "13   50.0   0.002343      12068          11976              92          10056   \n",
       "14   55.0  -0.495966      13275          12413             862           9286   \n",
       "15   60.0  -0.564497      14482          12686            1796           8352   \n",
       "16   65.0  -0.600024      15689          12871            2818           7330   \n",
       "17   70.0  -0.633855      16896          13064            3832           6316   \n",
       "18   75.0  -0.670906      18102          13279            4823           5325   \n",
       "19   80.0  -0.704614      19309          13519            5790           4358   \n",
       "20   85.0  -0.740393      20516          13702            6814           3334   \n",
       "21   90.0  -0.781814      21723          13841            7882           2266   \n",
       "22   95.0  -0.841766      22930          13958            8972           1176   \n",
       "23  100.0  -1.479267      24136          13989           10147              1   \n",
       "\n",
       "    false_negative  precision    recall        f1        f2  \n",
       "0            13747   1.000000  0.017299  0.034010  0.021531  \n",
       "1            13506   1.000000  0.034527  0.066750  0.042790  \n",
       "2            13264   1.000000  0.051826  0.098546  0.063954  \n",
       "3            13023   1.000000  0.069054  0.129188  0.084853  \n",
       "4            12782   1.000000  0.086282  0.158858  0.105575  \n",
       "5            11575   1.000000  0.172564  0.294336  0.206784  \n",
       "6            10368   1.000000  0.258846  0.411244  0.303892  \n",
       "7             9161   1.000000  0.345128  0.513153  0.397144  \n",
       "8             7955   1.000000  0.431339  0.602707  0.486691  \n",
       "9             6748   1.000000  0.517621  0.682148  0.572891  \n",
       "10            5542   0.999882  0.603832  0.752953  0.655782  \n",
       "11            4340   0.999482  0.689756  0.816225  0.735330  \n",
       "12            3144   0.998435  0.775252  0.872802  0.811533  \n",
       "13            2013   0.992377  0.856101  0.919216  0.880278  \n",
       "14            1576   0.935066  0.887340  0.910578  0.896491  \n",
       "15            1303   0.875984  0.906855  0.891152  0.900508  \n",
       "16            1118   0.820384  0.920080  0.867377  0.898248  \n",
       "17             925   0.773201  0.933877  0.845977  0.896612  \n",
       "18             710   0.733565  0.949246  0.827584  0.896527  \n",
       "19             470   0.700140  0.966402  0.812001  0.898093  \n",
       "20             287   0.667869  0.979484  0.794204  0.895883  \n",
       "21             148   0.637159  0.989420  0.775146  0.890910  \n",
       "22              31   0.608722  0.997784  0.756142  0.884694  \n",
       "23               0   0.579591  1.000000  0.733849  0.873308  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_score = eval_q_values[:, 1].numpy()\n",
    "eval_df = pd.DataFrame({'y_true': y_test, 'y_pred': y_test_score})\n",
    "threshold_analysis(eval_df, 'y_true', 'y_pred', tops=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "95b993b1-1dd0-4a80-b9b5-0576efdaa8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.002343\n",
    "test_df['predict'] = np.where(y_test_score >= threshold, 1, 0)\n",
    "test_df['predicted_reward'] = y_test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7345191c-9d65-4bb8-8aca-c9ba25e34aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Apply</th>\n",
       "      <th>Loan_Amount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predict</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12069</td>\n",
       "      <td>2013</td>\n",
       "      <td>78932000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12068</td>\n",
       "      <td>11976</td>\n",
       "      <td>478034000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID  Apply  Loan_Amount\n",
       "predict                           \n",
       "0        12069   2013   78932000.0\n",
       "1        12068  11976  478034000.0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.groupby('predict').agg({\n",
    "    'ID': 'count',\n",
    "    'Apply': 'sum',\n",
    "    'Loan_Amount': 'sum'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "49176f61-4d1a-49d0-8638-a7871c366a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_test_df = test_df.sort_values(by=['predicted_reward'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3d403a01-333b-453a-b81f-0662df432f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_Amount</th>\n",
       "      <th>predicted_reward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27490</th>\n",
       "      <td>120000.0</td>\n",
       "      <td>0.860846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29904</th>\n",
       "      <td>120000.0</td>\n",
       "      <td>0.735870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29907</th>\n",
       "      <td>120000.0</td>\n",
       "      <td>0.735870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27967</th>\n",
       "      <td>31000.0</td>\n",
       "      <td>0.728782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6127</th>\n",
       "      <td>120000.0</td>\n",
       "      <td>0.683959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6065</th>\n",
       "      <td>57000.0</td>\n",
       "      <td>0.683147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29963</th>\n",
       "      <td>53000.0</td>\n",
       "      <td>0.676961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5836</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>0.676686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28034</th>\n",
       "      <td>53000.0</td>\n",
       "      <td>0.675123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28920</th>\n",
       "      <td>30000.0</td>\n",
       "      <td>0.674933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7243</th>\n",
       "      <td>120000.0</td>\n",
       "      <td>0.671997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28189</th>\n",
       "      <td>120000.0</td>\n",
       "      <td>0.669006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6572</th>\n",
       "      <td>120000.0</td>\n",
       "      <td>0.667104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28916</th>\n",
       "      <td>42000.0</td>\n",
       "      <td>0.665200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28616</th>\n",
       "      <td>42000.0</td>\n",
       "      <td>0.665200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6573</th>\n",
       "      <td>59000.0</td>\n",
       "      <td>0.664999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29186</th>\n",
       "      <td>34000.0</td>\n",
       "      <td>0.664842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6299</th>\n",
       "      <td>54000.0</td>\n",
       "      <td>0.663923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27962</th>\n",
       "      <td>120000.0</td>\n",
       "      <td>0.663061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7190</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>0.662682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27695</th>\n",
       "      <td>38000.0</td>\n",
       "      <td>0.662046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29468</th>\n",
       "      <td>74000.0</td>\n",
       "      <td>0.661756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28599</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>0.661480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27740</th>\n",
       "      <td>49000.0</td>\n",
       "      <td>0.661166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7375</th>\n",
       "      <td>86000.0</td>\n",
       "      <td>0.661110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28113</th>\n",
       "      <td>91000.0</td>\n",
       "      <td>0.661027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29291</th>\n",
       "      <td>36000.0</td>\n",
       "      <td>0.659930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7283</th>\n",
       "      <td>64000.0</td>\n",
       "      <td>0.659736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7585</th>\n",
       "      <td>120000.0</td>\n",
       "      <td>0.658184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7573</th>\n",
       "      <td>120000.0</td>\n",
       "      <td>0.658184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Loan_Amount  predicted_reward\n",
       "27490     120000.0          0.860846\n",
       "29904     120000.0          0.735870\n",
       "29907     120000.0          0.735870\n",
       "27967      31000.0          0.728782\n",
       "6127      120000.0          0.683959\n",
       "6065       57000.0          0.683147\n",
       "29963      53000.0          0.676961\n",
       "5836      150000.0          0.676686\n",
       "28034      53000.0          0.675123\n",
       "28920      30000.0          0.674933\n",
       "7243      120000.0          0.671997\n",
       "28189     120000.0          0.669006\n",
       "6572      120000.0          0.667104\n",
       "28916      42000.0          0.665200\n",
       "28616      42000.0          0.665200\n",
       "6573       59000.0          0.664999\n",
       "29186      34000.0          0.664842\n",
       "6299       54000.0          0.663923\n",
       "27962     120000.0          0.663061\n",
       "7190      150000.0          0.662682\n",
       "27695      38000.0          0.662046\n",
       "29468      74000.0          0.661756\n",
       "28599     150000.0          0.661480\n",
       "27740      49000.0          0.661166\n",
       "7375       86000.0          0.661110\n",
       "28113      91000.0          0.661027\n",
       "29291      36000.0          0.659930\n",
       "7283       64000.0          0.659736\n",
       "7585      120000.0          0.658184\n",
       "7573      120000.0          0.658184"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_test_df.loc[:, ['Loan_Amount', 'predicted_reward']].head(30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mar_rl",
   "language": "python",
   "name": "mar_rl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
